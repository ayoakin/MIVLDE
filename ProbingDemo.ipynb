{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSwEot1F0P1QcVmaAR+H10"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# give colab permission to access drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm965IrO22Zw",
        "outputId": "b3a68a1c-d50a-4e1e-b326-762ae69cf12b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update these as required\n",
        "repo_path = '/content/drive/MyDrive/github/subteams/LLMProbing'\n",
        "odeformer_path = '/content/drive/MyDrive/aisc' # This is because I cloned the odeformer repo into my aisc folder\n",
        "samples_path = '/content/drive/MyDrive/github/subteams/LLMProbing/local_experiment_data/samples'\n",
        "activations_path = '/content/drive/MyDrive/github/subteams/LLMProbing/local_experiment_data/activations'\n",
        "probes_path = '/content/drive/MyDrive/github/subteams/LLMProbing/local_experiment_data/probes'"
      ],
      "metadata": {
        "id": "oMt_fcLwzfl6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import importlib\n",
        "sys.path.append(repo_path)\n",
        "sys.path.append(odeformer_path)"
      ],
      "metadata": {
        "id": "pNqQwNvG28hV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pickle"
      ],
      "metadata": {
        "id": "5RUno2Vs4e_g"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from odeformer.model import SymbolicTransformerRegressor\n",
        "dstr = SymbolicTransformerRegressor(from_pretrained=True)\n",
        "model_args = {'beam_size': 50, 'beam_temperature': 0.1}\n",
        "dstr.set_model_args(model_args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJCeXP3U7LML",
        "outputId": "121bd6b6-60a4-4701-cd4c-95ca1e240f26"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found pretrained model at odeformer.pt\n",
            "Loaded pretrained model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Sample Generation"
      ],
      "metadata": {
        "id": "4OANH6idzPaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from src.sample_generation import RandomSamplesGenerator\n",
        "# importlib.reload(RandomSamplesGenerator) # This doesn't work anymore since it's not reloading a module"
      ],
      "metadata": {
        "id": "LNbJcKUB3ES2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "operators_to_use = \"id:1,add:1,mul:1,sin:0.5\"\n",
        "min_dimension = 1\n",
        "max_dimension = 1\n",
        "num_samples = 10\n",
        "\n",
        "random_samples_path = f'{samples_path}/demo_random'"
      ],
      "metadata": {
        "id": "5ZdMR6G56J0S"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rsg = RandomSamplesGenerator(samples_path=random_samples_path, num_samples=num_samples, operators_to_use=operators_to_use, min_dimension=min_dimension, max_dimension=max_dimension)\n",
        "# TODO: possibly restructure this class to give important parameters to generate_random_samples()\n",
        "# Then we will be able to rerun generation with different parameters without having to instantiate a new instance of RSG\n",
        "# Probably what is most useful is to specify samples_path only"
      ],
      "metadata": {
        "id": "MR8m17Ck39QH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rsg.generate_random_samples()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaPYyAfR3J4e",
        "outputId": "262bd26c-2e83-4231-ae19-6f4d46c3e959"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Data generation complete. Saved 10 samples to /content/drive/MyDrive/github/subteams/LLMProbing/local_experiment_data/samples/demo_random\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect a random sample to see its keys and some data\n",
        "random_samples_dir = os.fsencode(random_samples_path)\n",
        "for random_sample_file in os.listdir(random_samples_dir):\n",
        "  random_sample_name = os.fsdecode(random_sample_file)\n",
        "  random_sample_path = os.path.join(random_samples_path, random_sample_name)\n",
        "  with open(random_sample_path, 'rb') as f:\n",
        "      random_sample = pickle.load(f)\n",
        "  print(random_sample.keys())\n",
        "  print(f\"Encoded equation: {random_sample['tree']}\")\n",
        "  print(f\"Feature dictionary: {random_sample['feature_dict']}\")\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMz8dSe-4AS1",
        "outputId": "4207d0fe-be09-4575-e9fd-e73b3eee02fe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['times', 'trajectory', 'tree_encoded', 'skeleton_tree_encoded', 'tree', 'skeleton_tree', 'infos', 'operator_dict', 'feature_dict'])\n",
            "Encoded equation: -0.2069 * (x_0)**2\n",
            "Feature dictionary: {'log': 0, 'exp': 0, 'tan': 0, 'arctan': 0, 'sin_cos': 0, 'arc_sin_cos': 0, 'pow2': 1, 'pow3': 0, 'inv': 0, 'sqrt': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manual Sample Generation"
      ],
      "metadata": {
        "id": "x3OpISsvzN25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from src.sample_generation import ManualSamplesGenerator"
      ],
      "metadata": {
        "id": "4d-5VwP7cBad"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "manual_samples_path = f'{samples_path}/demo_manual'\n",
        "msg = ManualSamplesGenerator(samples_path=manual_samples_path)"
      ],
      "metadata": {
        "id": "5GoSjUZezTbY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Times array\n",
        "t_values = np.linspace(1, 10, 50)\n",
        "\n",
        "# Exponential parameters\n",
        "c_values = np.linspace(-10,10, 2)\n",
        "a_values = np.linspace(-10,10, 5)\n",
        "\n",
        "# Hyperbolic parameters\n",
        "t0_values = np.linspace(10.1, 100, 5)"
      ],
      "metadata": {
        "id": "7waihYWV4KLN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate exponential samples\n",
        "msg.generate_exponential_samples(t_values, c_values, a_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4Buw9n65sr-",
        "outputId": "ad7a7aa0-b0a6-49b5-80a6-8ddb486babcc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Data generation complete. Saved 10 exponential samples to /content/drive/MyDrive/github/subteams/LLMProbing/local_experiment_data/samples/demo_manual\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect an exponential sample to see its keys and some data\n",
        "manual_samples_dir = os.fsencode(manual_samples_path)\n",
        "for sample_file in os.listdir(manual_samples_dir):\n",
        "  sample_name = os.fsdecode(sample_file)\n",
        "  if \"exp\" in sample_name:\n",
        "    exp_sample_path = os.path.join(manual_samples_path, sample_name)\n",
        "    with open(exp_sample_path, 'rb') as f:\n",
        "        exp_sample = pickle.load(f)\n",
        "    print(exp_sample.keys())\n",
        "    print(exp_sample['expression'])\n",
        "    print(exp_sample['feature_dict'])\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDBNG5ZC6hP0",
        "outputId": "3f83bea3-8ad7-41ed-92d6-2ec348d925a9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['times', 'trajectory', 'parameters', 'feature_dict', 'expression'])\n",
            "-10.0 * np.exp(10.0 * t)\n",
            "{'exponential': 1, 'hyperbolic': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate hyperbolic samples\n",
        "msg.generate_hyperbolic_samples(t_values, c_values, t0_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M2ADfC236CP",
        "outputId": "cec7a8fd-9f1c-484b-8446-8f4d98ffa8d1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Data generation complete. Saved 10 hyperbolic samples to /content/drive/MyDrive/github/subteams/LLMProbing/local_experiment_data/samples/demo_manual\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect a hyperbolic sample to see its keys and some data\n",
        "manual_samples_dir = os.fsencode(manual_samples_path)\n",
        "for sample_file in os.listdir(manual_samples_dir):\n",
        "  sample_name = os.fsdecode(sample_file)\n",
        "  if \"hyp\" in sample_name:\n",
        "    hyp_sample_path = os.path.join(manual_samples_path, sample_name)\n",
        "    with open(hyp_sample_path, 'rb') as f:\n",
        "        hyp_sample = pickle.load(f)\n",
        "    print(hyp_sample.keys())\n",
        "    print(hyp_sample['expression'])\n",
        "    print(hyp_sample['parameters'])\n",
        "    print(hyp_sample['feature_dict'])\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhZoC-MM6dsq",
        "outputId": "d730cbfa-05bd-4f26-81eb-86b753f0c6b6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['times', 'trajectory', 'parameters', 'feature_dict', 'expression'])\n",
            "-10.0 / (10.1-t)\n",
            "{'t0': 10.1, 'c': -10.0}\n",
            "{'exponential': 0, 'hyperbolic': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Corresponding Activations Extraction"
      ],
      "metadata": {
        "id": "frWKyg3szUQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from src.activation_extraction import ActivationsExtractor"
      ],
      "metadata": {
        "id": "gV07FbFXzYy_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_activations_path = f'{activations_path}/demo_random'\n",
        "manual_activations_path = f'{activations_path}/demo_manual'"
      ],
      "metadata": {
        "id": "93-zzRtQIshT"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "act_extractor = ActivationsExtractor()"
      ],
      "metadata": {
        "id": "wqT_igPg6wvD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "act_extractor.extract_activations(dstr, random_samples_path, random_activations_path, layers_to_extract=['ffn'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4Ind3Yx-b3x",
        "outputId": "6b07294d-c962-4a93-d7ed-de96ebaa7fbf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Activations: 100%|██████████| 10/10 [00:51<00:00,  5.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Activation extraction complete. Activations saved to /content/drive/MyDrive/github/subteams/LLMProbing/local_experiment_data/activations/demo_random\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "act_extractor.extract_activations(dstr, manual_samples_path, manual_activations_path, layers_to_extract=['ffn'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "SLMfIh5nI7hH",
        "outputId": "eef40869-a4d5-4c2e-f40c-eb0a60242059"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Activations:   5%|▌         | 1/20 [01:09<22:04, 69.69s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidParameterError",
          "evalue": "The 'y_pred' parameter of r2_score must be an array-like. Got None instead.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-42fca06cb40b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mact_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_activations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmanual_samples_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmanual_activations_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers_to_extract\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ffn'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/drive/MyDrive/github/subteams/LLMProbing/src/activation_extraction/activations_extractor.py\u001b[0m in \u001b[0;36mextract_activations\u001b[0;34m(self, dstr, samples_path, activations_path, layers_to_extract)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;31m# Compute and add R^2 score (this adds a little extra overhead each iteration)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mpred_trajectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'times'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trajectory'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mtest_r2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trajectory'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_trajectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'r2_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_r2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_ignore\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             validate_parameter_constraints(\n\u001b[0m\u001b[1;32m    207\u001b[0m                 \u001b[0mparameter_constraints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaller_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 )\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             raise InvalidParameterError(\n\u001b[0m\u001b[1;32m     99\u001b[0m                 \u001b[0;34mf\"The {param_name!r} parameter of {caller_name} must be\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34mf\" {constraints_str}. Got {param_val!r} instead.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidParameterError\u001b[0m: The 'y_pred' parameter of r2_score must be an array-like. Got None instead."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect a random activation and display its keys and some values\n",
        "random_acts_dir = os.fsencode(random_activations_path)\n",
        "for acts_file in os.listdir(random_acts_dir):\n",
        "  acts_name = os.fsdecode(acts_file)\n",
        "  random_acts_path = os.path.join(random_activations_path, acts_name)\n",
        "  with open(random_acts_path, 'rb') as f:\n",
        "      random_acts = pickle.load(f)\n",
        "  print(random_acts.keys())\n",
        "  print(random_acts['feature_dict'])\n",
        "  print(random_acts['r2_score'])\n",
        "  print(random_acts['expression'])\n",
        "  print(random_acts['pred_expression'])\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcaqVrXl_VbH",
        "outputId": "e213bbe6-a306-46f2-e57c-a586cfd56a4e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['encoder', 'decoder', 'operator_dict', 'feature_dict', 'r2_score', 'pred_expression', 'expression'])\n",
            "{'log': 0, 'exp': 0, 'tan': 0, 'arctan': 0, 'sin_cos': 0, 'arc_sin_cos': 0, 'pow2': 1, 'pow3': 0, 'inv': 0, 'sqrt': 0}\n",
            "0.9991958011706891\n",
            "0.5489 * (x_0)**2\n",
            "x_0' = 0.5675 * (x_0)**2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect a manual activation and display its keys and some values\n",
        "manual_acts_dir = os.fsencode(manual_activations_path)\n",
        "for acts_file in os.listdir(manual_acts_dir):\n",
        "  acts_name = os.fsdecode(acts_file)\n",
        "  manual_acts_path = os.path.join(manual_activations_path, acts_name)\n",
        "  with open(manual_acts_path, 'rb') as f:\n",
        "      manual_acts = pickle.load(f)\n",
        "  print(manual_acts.keys())\n",
        "  print(manual_acts['feature_dict'])\n",
        "  print(manual_acts['r2_score'])\n",
        "  print(manual_acts['expression'])\n",
        "  print(manual_acts['pred_expression'])\n",
        "  break"
      ],
      "metadata": {
        "id": "AOeQAVnUJotp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Probe Training"
      ],
      "metadata": {
        "id": "LLY7KIPHzZrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: add experiment runner file to make it easy to specify layers and features?\n",
        "from experiments.run_experiment import separability_testing"
      ],
      "metadata": {
        "id": "62wGV9swzbMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_feature = 'exponential'\n",
        "# activations_path = manual_activations_path\n",
        "demo_probes_path = f'{probes_path}/demo_exp'\n",
        "lr = 0.01\n",
        "num_epochs = 1\n",
        "layers = [idx for idx in range(4, 16)]"
      ],
      "metadata": {
        "id": "4k6snzo5fm-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo_expt_results = separability_testing(target_feature=target_feature, activations_path=manual_activations_path, \\\n",
        "                     probes_path=demo_probes_path, \\\n",
        "                     lr=lr, num_epochs=num_epochs, \\\n",
        "                     layers=layers)"
      ],
      "metadata": {
        "id": "Sgr-mGCVhJG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: view and summarise experiment results"
      ],
      "metadata": {
        "id": "WaqEyQp7m3U5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Probe Loading and Evaluation"
      ],
      "metadata": {
        "id": "LcY7GtWxzbgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: write extra loading functionality for running an experiment using pretrained\n",
        "# TODO: extend failure detection functionality"
      ],
      "metadata": {
        "id": "-cctwkQazc8Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
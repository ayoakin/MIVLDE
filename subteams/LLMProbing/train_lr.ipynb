{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCOSERK/IcuREGCPZdiDaK"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LU9k4EGMcAYP",
        "outputId": "c423d297-6bef-4f6a-d6c2-e368a5f52de4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GRyFq_JRXyfX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader, Dataset, random_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "repo_path = '/content/drive/MyDrive/odeformer' # folder where odeformer is stored\n",
        "script_path = '/content/drive/MyDrive/aisc' # folder containing the script generate_samples.py\n",
        "activations_path = '/content/drive/MyDrive/aisc/activations' # where you want to save activations\n",
        "logs_path = '/content/drive/MyDrive/aisc/logs'\n",
        "probes_path = '/content/drive/MyDrive/aisc/probes'\n",
        "%cd {script_path}\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Q14vL7L6Udw",
        "outputId": "7c9155c7-6e05-4f46-c8c8-b22b59daa5ef"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/aisc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LRProbe and ActivationsDataset classes"
      ],
      "metadata": {
        "id": "Xc1Xg79OJ1VJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Probe class\n",
        "\n",
        "class LRProbe(torch.nn.Module):\n",
        "    def __init__(self, d_in=512): # Default decoder layer activation dimension\n",
        "        super().__init__()\n",
        "        self.net = torch.nn.Sequential(\n",
        "            torch.nn.Linear(d_in, 1, bias=False),\n",
        "            torch.nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x).squeeze(-1) # I just copied this. I don't know if .squeeze is necessary?\n",
        "\n",
        "    def predict(self, acts):\n",
        "        with torch.no_grad():\n",
        "            return self(acts)\n",
        "\n",
        "    @property\n",
        "    def direction(self):\n",
        "        return self.net[0].weight.data[0]"
      ],
      "metadata": {
        "id": "mB718wZVb7Y5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch wrapper for activations dataset\n",
        "\n",
        "class ActivationsDataset(Dataset):\n",
        "  def __init__(self, activations_path, feature_label, layer_idx, module='ffn'):\n",
        "    self.act_paths = [os.path.join(activations_path, f) for f in os.listdir(activations_path)]\n",
        "    self.feature_label = feature_label\n",
        "    self.layer_idx = layer_idx\n",
        "    self.module = module\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.act_paths)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    act_path = self.act_paths[idx]\n",
        "    # TODO: need to change from torch load to pickle\n",
        "    activation = torch.load(act_path)\n",
        "    layer_name = self.get_layer_name(self.layer_idx)\n",
        "    if 'encoder' in layer_name:\n",
        "      act_data = activation['encoder'][layer_name]\n",
        "    else:\n",
        "      act_data = activation['decoder'][layer_name]\n",
        "    # TODO: will need to update the below functionality when the activations\n",
        "    #       script is changed to collect only activations for the final token\n",
        "    act_data = act_data[-1, :, :].flatten()\n",
        "    act_label = torch.tensor(activation['feature_dict'][self.feature_label], dtype=torch.float)\n",
        "    return act_data, act_label\n",
        "\n",
        "  def get_layer_name(self, idx):\n",
        "    '''\n",
        "    Helper function to return the correct name of a layer in the ODEFormer given\n",
        "    its index\n",
        "    '''\n",
        "    layers = [f'encoder_{self.module}_{num}' for num in range(4)] + [f'decoder_{self.module}_{num}' for num in range(12)]\n",
        "    layer_name = layers[idx]\n",
        "    if -16 <= idx < 16:\n",
        "      return layer_name\n",
        "    else:\n",
        "      raise ValueError(\"Layer index should be in -16 to 15\")"
      ],
      "metadata": {
        "id": "vOYis1Unt2QM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper functions"
      ],
      "metadata": {
        "id": "vShwG-O1KD7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset helper functions\n",
        "\n",
        "def split_dataset(dataset, lengths=[0.8, 0.0, 0.2], seed=None):\n",
        "  '''\n",
        "  Split into training, validation, and testing datasets\n",
        "  Default is to have no validation dataset (i.e. empty) and randomized splitting\n",
        "  Seed can be set for deterministic splitting\n",
        "  '''\n",
        "  generator = torch.Generator().manual_seed(seed)\n",
        "  return random_split(dataset, lengths, generator)\n",
        "\n",
        "def get_d_in(dataset):\n",
        "  '''\n",
        "  Return the input dimension a probe requires for a given dataset of activations\n",
        "  '''\n",
        "  d_in = dataset[0][0].shape[0]\n",
        "  return d_in"
      ],
      "metadata": {
        "id": "D8ZQBXMq-0Aa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Probe training and evaluation functions\n",
        "\n",
        "def eval_probe(probe, dataloader):\n",
        "  '''\n",
        "  Evaluate a given probe on a specified dataset (via its corresponding dataloader)\n",
        "  '''\n",
        "  with torch.no_grad():\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total_preds = 0\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    probe.eval()\n",
        "\n",
        "    for acts, labels in dataloader:\n",
        "      outputs = probe(acts)\n",
        "      preds = outputs.round()\n",
        "      loss = criterion(preds, labels)\n",
        "      total_loss += loss.item()\n",
        "      correct += (preds == labels).float().sum()\n",
        "      total_preds += len(labels)\n",
        "\n",
        "    accuracy = (correct / total_preds).item()\n",
        "    avg_loss = total_loss / total_preds\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "def train_probe(probe, train_dataloader, val_dataloader=None, \\\n",
        "                lr=0.01, epochs=20, device='cpu', \\\n",
        "                logs_path='/content/drive/MyDrive/aisc/logs', write_log=False): # TODO: determine if default hyperparameters are good\n",
        "  '''\n",
        "  Train an instantiated probe using specified training and validation data\n",
        "  '''\n",
        "  # Use Adam optimizer for now; TODO: determine if other optimizers might be better\n",
        "  opt = optim.Adam(probe.parameters(), lr=lr)\n",
        "  criterion = nn.BCELoss()\n",
        "\n",
        "  # Open log files to write to if desired\n",
        "  # Include the current time of the experiment in filename to avoid collisions\n",
        "  today_str = datetime.datetime.now().strftime('%Y_%m_%d_%H_%M')\n",
        "  if write_log:\n",
        "    train_f = open(os.path.join(logs_path, f'{today_str}_train_acc_per_epoch.txt'), 'w')\n",
        "    if val_dataloader is not None:\n",
        "      val_f = open(os.path.join(logs_path, f'{today_str}_val_acc_per_epoch.txt'), 'w')\n",
        "\n",
        "  # Main training loop\n",
        "  for epoch in tqdm(range(epochs), desc='Training LR Probe'):\n",
        "    probe.train()\n",
        "\n",
        "    total_loss = 0\n",
        "    correct_preds = 0\n",
        "    total_preds = 0\n",
        "\n",
        "    for train_acts, train_labels in train_dataloader:\n",
        "      # Calculate batch loss\n",
        "      opt.zero_grad()\n",
        "      outputs = probe(train_acts)\n",
        "      loss = criterion(outputs, train_labels)\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      total_loss += loss.item()\n",
        "      total_preds += len(train_labels)\n",
        "\n",
        "      # Calculate correct batch predictions\n",
        "      preds = outputs.round()\n",
        "      correct_preds += (preds == train_labels).float().sum()\n",
        "\n",
        "    # Calculate epoch stats\n",
        "    accuracy = (correct_preds / total_preds).item()\n",
        "    avg_loss = total_loss / total_preds\n",
        "\n",
        "    # Write to specified log file\n",
        "    if write_log:\n",
        "      train_f.write(f'Epoch {epoch+1}: Loss {avg_loss}, Accuracy {accuracy}\\n')\n",
        "    # print(f' Epoch {epoch+1}: Loss {avg_loss}, Accuracy {accuracy.item()}\\n')\n",
        "\n",
        "    # TODO: maybe implement early stopping? Need to test on larger dataset\n",
        "    # Run evaluation on validation set\n",
        "    if val_dataloader is not None:\n",
        "        avg_val_loss, val_accuracy = eval_probe(probe, val_dataloader)\n",
        "        if write_log:\n",
        "          val_f.write(f'Epoch {epoch+1} (Validation): Loss {avg_val_loss}, Accuracy {val_accuracy.item()}\\n')\n",
        "        # print(f' Epoch {epoch+1} (Validation): Loss {avg_val_loss}, Accuracy {val_accuracy.item()}\\n')\n",
        "\n",
        "  print(f'\\nEpoch {epoch+1} (Final): Loss {avg_loss}, Accuracy {accuracy}')\n",
        "\n",
        "  # TODO: return also train and val accuracy arrays for easy plotting?\n",
        "  return probe"
      ],
      "metadata": {
        "id": "LfrvbW4Db9nw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Probe saving and loading functionality\n",
        "\n",
        "def save_probe_to_path(probe, probe_path):\n",
        "  '''\n",
        "  Save a probe's state dictionary to a specified path\n",
        "  (saving only the state dictionary is suggested by PyTorch)\n",
        "  '''\n",
        "  torch.save(probe.state_dict(), probe_path)\n",
        "  print(f'Saved state dictionary to {probe_path}')\n",
        "\n",
        "def load_probe_from_path(probe_path, d_in=512):\n",
        "  '''\n",
        "  Returns a probe ready for evaluation loaded from the given path, with specified input dimension\n",
        "  '''\n",
        "  probe = LRProbe(d_in=d_in)\n",
        "  probe.load_state_dict(torch.load(probe_path, weights_only=True))\n",
        "  probe.eval()\n",
        "  return probe"
      ],
      "metadata": {
        "id": "TS3gdBujhidY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MWE and features testing\n",
        "\n",
        "# Test dataset, dataloaders, and splitting\n",
        "target_feature = 'trig'\n",
        "target_layer_idx = 15\n",
        "full_dataset = ActivationsDataset(activations_path=activations_path, feature_label=target_feature, layer_idx=target_layer_idx)\n",
        "train_dataset, val_dataset, test_dataset = split_dataset(full_dataset, lengths=[0.7, 0.1, 0.2], seed=42)\n",
        "train_dataloader = DataLoader(train_dataset)\n",
        "val_dataloader = DataLoader(val_dataset)\n",
        "test_dataloader = DataLoader(test_dataset)\n",
        "\n",
        "# Test helper function and probe\n",
        "d_in = get_d_in(full_dataset)\n",
        "test_probe = LRProbe(d_in)\n",
        "\n",
        "# Test training loop\n",
        "train_probe(test_probe, train_dataloader, val_dataloader=val_dataloader)\n",
        "\n",
        "# Test evaluation function on test set\n",
        "test_loss, test_acc = eval_probe(test_probe, test_dataloader)\n",
        "print(f'Test Set: Loss {test_loss}, Accuracy {test_acc}')\n",
        "\n",
        "# Test extracting saved probe direction\n",
        "print(f'Probe direction dim: {test_probe.direction.shape}')\n",
        "\n",
        "# Test saving and loading probe\n",
        "probe_name = f'test_probe_{target_feature}_{target_layer_idx}.pt'\n",
        "test_probe_path = os.path.join(probes_path, probe_name)\n",
        "save_probe_to_path(test_probe, test_probe_path)\n",
        "test_probe_copy = load_probe_from_path(test_probe_path, d_in=d_in)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eu7bwnxr3H6w",
        "outputId": "2a1a8901-21fe-4b42-94da-edd3acd41f22"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-0a8bc0f92ce0>:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  activation = torch.load(act_path)\n",
            "Training LR Probe: 100%|██████████| 20/20 [00:02<00:00,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 20 (Final): Loss 6.269478007275049e-05, Accuracy 1.0\n",
            "Test Set: Loss 50.0, Accuracy 0.5\n",
            "Probe direction dim: torch.Size([512])\n",
            "Saved state dictionary to /content/drive/MyDrive/aisc/probes/test_probe_trig_15.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"3O1_xYzpFiJ5"}},{"cell_type":"code","source":["# give colab permission to access drive (I had to give it all permissions before this would work...)\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","repo_path = '/content/drive/MyDrive/odeformer' # folder where odeformer is stored\n","samples_path = '/content/drive/MyDrive/aisc/samples' # where you want to save samples\n","activations_path = '/content/drive/MyDrive/aisc/activations' # where you want to save activations\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C0d3LDd6UY-c","outputId":"bbda33b5-b4ca-4ab1-b5f7-4609cab7fd71","executionInfo":{"status":"ok","timestamp":1740160411920,"user_tz":0,"elapsed":19865,"user":{"displayName":"Helen Saville","userId":"00129041141670569484"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import sys\n","\n","sys.path.append(repo_path)\n","sys.path.append(repo_path + \"/odeformer\")\n","sys.path.append(repo_path + \"odeformer/envs\")"],"metadata":{"id":"dEVTRc_dKSlo","executionInfo":{"status":"ok","timestamp":1740160411922,"user_tz":0,"elapsed":5,"user":{"displayName":"Helen Saville","userId":"00129041141670569484"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# clone odeformer into google drive (if needed)\n","# !git clone https://github.com/sdascoli/odeformer.git {aisc_folder}"],"metadata":{"id":"GAfATLyiVYS7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# not required on colab?\n","# !pip install --quiet numexpr sympy==1.11.1 matplotlib numpy pandas requests scikit-learn scipy seaborn setproctitle torch tqdm wandb gdown regex"],"metadata":{"id":"DiQoxpwFWxPu","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ae1b50dc-499c-4f9d-e553-d2067d56f58a","collapsed":true,"executionInfo":{"status":"ok","timestamp":1740160252684,"user_tz":0,"elapsed":200673,"user":{"displayName":"Helen Saville","userId":"00129041141670569484"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m833.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.4.1 which is incompatible.\n","torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["import uuid\n","import json\n","import os\n","import numpy as np\n","import torch\n","import re\n","\n","try:\n","    from odeformer.envs.environment import FunctionEnvironment\n","    from parsers import get_parser\n","except ModuleNotFoundError as e:\n","    print(\"[ERROR] Could not import odeformer. Check path and installation.\")\n","    raise e"],"metadata":{"id":"vcTRuNAKHMCV","executionInfo":{"status":"ok","timestamp":1740160459116,"user_tz":0,"elapsed":9430,"user":{"displayName":"Helen Saville","userId":"00129041141670569484"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Sample generation"],"metadata":{"id":"nH5umWchFlNc"}},{"cell_type":"code","source":["# get params as arg for creating the function environment\n","# need to check the default params set in get_parser()\n","parser = get_parser()\n","params = parser.parse_args(args=[\"--operators_to_use\", \"add:1,id:1,pow2:1,pow3:1,inv:1\", \"--min_dimension\", \"1\", \"--max_dimension\", \"1\"])\n","# create function environment, which is able to generate samples\n","env = FunctionEnvironment(params)"],"metadata":{"id":"Ka86cRgCWFN8","executionInfo":{"status":"ok","timestamp":1740162849062,"user_tz":0,"elapsed":37,"user":{"displayName":"Helen Saville","userId":"00129041141670569484"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["def identify_operators(sample):\n","    operators_real = {\n","      \"add\": 2, \"sub\": 2, \"mul\": 2, \"div\": 2, \"abs\": 1, \"inv\": 1, \"sqrt\": 1,\n","      \"log\": 1, \"exp\": 1, \"sin\": 1, \"arcsin\": 1, \"cos\": 1, \"arccos\": 1,\n","      \"tan\": 1, \"arctan\": 1, \"pow2\": 1, \"pow3\": 1, 'id': 1\n","    }\n","    operators_extra = {\"pow\": 2}\n","    all_operators = {**operators_real, **operators_extra}\n","\n","    skeleton_tree_encoded = sample['skeleton_tree_encoded']\n","    operator_dict = {operator: 1 if operator in skeleton_tree_encoded else 0 for operator in all_operators}\n","    sample['operator_dict'] = operator_dict\n","    return sample"],"metadata":{"id":"FeoSVwfwQqMA","executionInfo":{"status":"ok","timestamp":1740160465424,"user_tz":0,"elapsed":8,"user":{"displayName":"Helen Saville","userId":"00129041141670569484"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def identify_features(sample):\n","\n","    def identify_multiple_features(feature_operators, feature_name, operator_dict):\n","        if any(operator_dict.get(operator, 0) == 1 for operator in feature_operators):\n","            feature_dict[feature_name] = 1\n","        else:\n","            feature_dict[feature_name] = 0\n","\n","    trig_funs = ['sin', 'cos', 'tan']\n","    inv_trig_funs = ['arcsin', 'arccos', 'arctan']\n","    features_single = ['pow2', 'pow3', 'log', 'sqrt', 'exp']\n","\n","\n","    operator_dict = sample['operator_dict']\n","    feature_dict = {}\n","\n","    for feature in features_single:\n","      feature_dict[feature] = operator_dict[feature]\n","\n","    identify_multiple_features(trig_funs, 'trig', operator_dict)\n","    identify_multiple_features(inv_trig_funs, 'inv_trig', operator_dict)\n","\n","    sample['feature_dict'] = feature_dict\n","    return sample"],"metadata":{"id":"CHKYnnthWhxS","executionInfo":{"status":"ok","timestamp":1740160466921,"user_tz":0,"elapsed":7,"user":{"displayName":"Helen Saville","userId":"00129041141670569484"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["**Information about samples**\n","\n","Each sample is a dictionary with entries:\n","1. times,\n","2. trajectory,\n","3. tree_encoded: prefix notation, as list of operators and exact constants\n","4. skeleton_tree_encoded: same as above, but with 'CONSTANT' instead of constants' values\n","5. tree\n","6. skeleton_tree: same as (4) but normal maths expression rather than prefix notation\n","7. infos: number of points, number of unary and binary operators, dimension\n","\n","The following is adapted from Helen's notebook / file on sample generation; https://github.com/ayoakin/MIVLDE/blob/LLMProbing/subteams/LLMProbing/sample_generation/generate_samples.py"],"metadata":{"id":"pZz5HDxheI-7"}},{"cell_type":"code","source":["os.makedirs(samples_path, exist_ok=True)\n","seed = 42 # Set seed for deterministic sample generation (for now)\n","# seed = None # Random seed (turn on if wanted)\n","seed_gen = np.random.RandomState(seed)"],"metadata":{"id":"5Yu-FbC2aQ7v","executionInfo":{"status":"ok","timestamp":1740160469741,"user_tz":0,"elapsed":7,"user":{"displayName":"Helen Saville","userId":"00129041141670569484"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["n_samples = 100\n","# samples = [] # for testing\n","\n","for i in range(n_samples):\n","  sample_seed = seed_gen.randint(1_000_000_000)\n","  # Number copied somewhere from their github (https://github.com/sdascoli/odeformer/blob/c9193012ad07a97186290b98d8290d1a177f4609/odeformer/trainer.py#L244)\n","  # May need to set with more care?\n","  env.rng = np.random.RandomState(sample_seed)\n","  sample, errors = env.gen_expr(train=True)\n","  sample = identify_operators(sample)\n","  sample = identify_features(sample)\n","\n","  # Generate filename\n","  sample_filename = f\"sample_{sample_seed}.pt\"\n","  sample_filepath = os.path.join(samples_path, sample_filename)\n","\n","\n","  # Save file using torch with pickle\n","  with open(sample_filepath, 'wb') as f:\n","    pickle.dump(sample, f)\n","  print(f\"[INFO] Saved to {sample_filepath}\")\n","  # samples.append(sample) # for testing\n","\n","print(\"[INFO] Data generation complete.\")\n","\n","# for testing\n","# for sample in samples:\n","#   if sample['operator_dict']['inv']:\n","#       print('this sample has inv')\n","#       print(sample['skeleton_tree_encoded'])\n","#       print(sample['skeleton_tree'])\n","#   if sample['operator_dict']['pow2']:\n","#       print('this sample has pow2')\n","#       print(sample['skeleton_tree_encoded'])\n","#       print(sample['skeleton_tree'])\n","#   if sample['operator_dict']['pow3']:\n","#       print('this sample has pow3')\n","#       print(sample['skeleton_tree_encoded'])\n","#       print(sample['skeleton_tree'])\n","# for sample in samples:\n","#   print(sample['skeleton_tree_encoded'])\n","#   print(sample['skeleton_tree'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ETfoQJ-BjAE1","outputId":"ff9c2d8f-0fa3-445f-8fa7-277b949255ff","collapsed":true,"executionInfo":{"status":"ok","timestamp":1740162919913,"user_tz":0,"elapsed":58060,"user":{"displayName":"Helen Saville","userId":"00129041141670569484"}}},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] Data generation complete.\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['add', 'mul', 'CONSTANT', 'pow', 'add', 'CONSTANT', 'mul', 'CONSTANT', 'x_0', 'INT-', '1', 'mul', 'CONSTANT', 'pow', 'x_0', 'INT-', '1']\n","CONSTANT * (CONSTANT + CONSTANT * x_0)**-1 + CONSTANT * (x_0)**-1\n","['add', 'mul', 'CONSTANT', 'pow', 'add', 'mul', 'INT-', '1', 'pow', 'add', 'CONSTANT', 'mul', 'CONSTANT', 'x_0', 'INT-', '1', 'mul', 'CONSTANT', 'x_0', 'INT+', '2', 'mul', 'CONSTANT', 'pow', 'add', 'CONSTANT', 'mul', 'CONSTANT', 'x_0', 'INT-', '1']\n","CONSTANT * (-1 * (CONSTANT + CONSTANT * x_0)**-1 + CONSTANT * x_0)**2 + CONSTANT * (CONSTANT + CONSTANT * x_0)**-1\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['add', 'mul', 'CONSTANT', 'pow', 'add', 'CONSTANT', 'mul', 'CONSTANT', 'x_0', 'INT-', '1', 'mul', 'CONSTANT', 'x_0']\n","CONSTANT * (CONSTANT + CONSTANT * x_0)**-1 + CONSTANT * x_0\n","['add', 'mul', 'CONSTANT', 'x_0', 'mul', 'CONSTANT', 'pow', 'add', 'INT-', '1', 'mul', 'CONSTANT', 'x_0', 'INT+', '3']\n","CONSTANT * x_0 + CONSTANT * (-1 + CONSTANT * x_0)**3\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['add', 'mul', 'CONSTANT', 'pow', 'add', 'x_0', 'mul', 'CONSTANT', 'pow', 'add', 'CONSTANT', 'mul', 'CONSTANT', 'x_0', 'INT-', '1', 'INT+', '3', 'mul', 'CONSTANT', 'x_0']\n","CONSTANT * (x_0 + CONSTANT * (CONSTANT + CONSTANT * x_0)**-1)**3 + CONSTANT * x_0\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['add', 'mul', 'CONSTANT', 'x_0', 'mul', 'CONSTANT', 'pow', 'add', 'CONSTANT', 'x_0', 'INT+', '3']\n","CONSTANT * x_0 + CONSTANT * (CONSTANT + x_0)**3\n","['add', 'mul', 'CONSTANT', 'pow', 'add', 'CONSTANT', 'x_0', 'INT+', '3', 'mul', 'CONSTANT', 'pow', 'add', 'INT+', '1', 'mul', 'CONSTANT', 'x_0', 'INT+', '3']\n","CONSTANT * (CONSTANT + x_0)**3 + CONSTANT * (1 + CONSTANT * x_0)**3\n","['add', 'CONSTANT', 'mul', 'CONSTANT', 'x_0']\n","CONSTANT + CONSTANT * x_0\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['add', 'CONSTANT', 'add', 'mul', 'CONSTANT', 'pow', 'x_0', 'INT+', '2', 'mul', 'CONSTANT', 'x_0']\n","CONSTANT + CONSTANT * (x_0)**2 + CONSTANT * x_0\n","['add', 'CONSTANT', 'mul', 'CONSTANT', 'x_0']\n","CONSTANT + CONSTANT * x_0\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['add', 'CONSTANT', 'mul', 'CONSTANT', 'x_0']\n","CONSTANT + CONSTANT * x_0\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['add', 'CONSTANT', 'mul', 'CONSTANT', 'x_0']\n","CONSTANT + CONSTANT * x_0\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['add', 'mul', 'CONSTANT', 'x_0', 'add', 'mul', 'CONSTANT', 'pow', 'add', 'CONSTANT', 'x_0', 'INT+', '2', 'mul', 'CONSTANT', 'pow', 'add', 'INT-', '1', 'mul', 'CONSTANT', 'x_0', 'INT+', '3']\n","CONSTANT * x_0 + CONSTANT * (CONSTANT + x_0)**2 + CONSTANT * (-1 + CONSTANT * x_0)**3\n","['add', 'mul', 'CONSTANT', 'x_0', 'mul', 'CONSTANT', 'pow', 'add', 'INT+', '1', 'mul', 'CONSTANT', 'x_0', 'INT+', '2']\n","CONSTANT * x_0 + CONSTANT * (1 + CONSTANT * x_0)**2\n","['add', 'mul', 'CONSTANT', 'x_0', 'mul', 'CONSTANT', 'pow', 'add', 'INT+', '1', 'mul', 'CONSTANT', 'x_0', 'INT+', '3']\n","CONSTANT * x_0 + CONSTANT * (1 + CONSTANT * x_0)**3\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['add', 'CONSTANT', 'mul', 'CONSTANT', 'x_0']\n","CONSTANT + CONSTANT * x_0\n","['add', 'mul', 'CONSTANT', 'pow', 'x_0', 'INT-', '1', 'mul', 'CONSTANT', 'x_0']\n","CONSTANT * (x_0)**-1 + CONSTANT * x_0\n","['add', 'mul', 'CONSTANT', 'pow', 'add', 'CONSTANT', 'mul', 'INT-', '1', 'x_0', 'INT+', '2', 'mul', 'CONSTANT', 'x_0']\n","CONSTANT * (CONSTANT + -1 * x_0)**2 + CONSTANT * x_0\n","['add', 'mul', 'CONSTANT', 'pow', 'add', 'CONSTANT', 'mul', 'CONSTANT', 'x_0', 'INT-', '1', 'add', 'mul', 'CONSTANT', 'pow', 'add', 'CONSTANT', 'x_0', 'INT+', '2', 'add', 'mul', 'CONSTANT', 'x_0', 'mul', 'CONSTANT', 'pow', 'add', 'CONSTANT', 'mul', 'INT-', '1', 'x_0', 'INT+', '2']\n","CONSTANT * (CONSTANT + CONSTANT * x_0)**-1 + CONSTANT * (CONSTANT + x_0)**2 + CONSTANT * x_0 + CONSTANT * (CONSTANT + -1 * x_0)**2\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['add', 'CONSTANT', 'mul', 'CONSTANT', 'x_0']\n","CONSTANT + CONSTANT * x_0\n","['add', 'mul', 'CONSTANT', 'x_0', 'add', 'mul', 'CONSTANT', 'pow', 'add', 'CONSTANT', 'mul', 'CONSTANT', 'x_0', 'INT-', '1', 'mul', 'CONSTANT', 'pow', 'x_0', 'INT+', '3']\n","CONSTANT * x_0 + CONSTANT * (CONSTANT + CONSTANT * x_0)**-1 + CONSTANT * (x_0)**3\n","['add', 'mul', 'CONSTANT', 'x_0', 'mul', 'CONSTANT', 'pow', 'add', 'INT+', '1', 'mul', 'CONSTANT', 'x_0', 'INT+', '2']\n","CONSTANT * x_0 + CONSTANT * (1 + CONSTANT * x_0)**2\n","['add', 'mul', 'CONSTANT', 'x_0', 'add', 'mul', 'CONSTANT', 'pow', 'add', 'INT-', '1', 'mul', 'CONSTANT', 'x_0', 'INT+', '3', 'add', 'mul', 'CONSTANT', 'pow', 'x_0', 'INT-', '1', 'mul', 'CONSTANT', 'pow', 'add', 'INT-', '1', 'mul', 'CONSTANT', 'x_0', 'INT+', '2']\n","CONSTANT * x_0 + CONSTANT * (-1 + CONSTANT * x_0)**3 + CONSTANT * (x_0)**-1 + CONSTANT * (-1 + CONSTANT * x_0)**2\n","['add', 'CONSTANT', 'add', 'mul', 'CONSTANT', 'pow', 'add', 'INT+', '1', 'mul', 'CONSTANT', 'x_0', 'INT+', '2', 'mul', 'CONSTANT', 'x_0']\n","CONSTANT + CONSTANT * (1 + CONSTANT * x_0)**2 + CONSTANT * x_0\n","['add', 'mul', 'CONSTANT', 'x_0', 'mul', 'CONSTANT', 'pow', 'x_0', 'INT-', '1']\n","CONSTANT * x_0 + CONSTANT * (x_0)**-1\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['add', 'CONSTANT', 'mul', 'CONSTANT', 'x_0']\n","CONSTANT + CONSTANT * x_0\n","['mul', 'CONSTANT', 'pow', 'x_0', 'INT+', '3']\n","CONSTANT * (x_0)**3\n","['add', 'CONSTANT', 'add', 'mul', 'CONSTANT', 'pow', 'x_0', 'INT-', '1', 'mul', 'CONSTANT', 'x_0']\n","CONSTANT + CONSTANT * (x_0)**-1 + CONSTANT * x_0\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['add', 'mul', 'CONSTANT', 'x_0', 'mul', 'CONSTANT', 'pow', 'add', 'CONSTANT', 'mul', 'CONSTANT', 'x_0', 'INT-', '1']\n","CONSTANT * x_0 + CONSTANT * (CONSTANT + CONSTANT * x_0)**-1\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['add', 'mul', 'CONSTANT', 'pow', 'add', 'INT+', '1', 'mul', 'CONSTANT', 'x_0', 'INT+', '3', 'mul', 'CONSTANT', 'pow', 'add', 'CONSTANT', 'x_0', 'INT+', '3']\n","CONSTANT * (1 + CONSTANT * x_0)**3 + CONSTANT * (CONSTANT + x_0)**3\n","['add', 'CONSTANT', 'mul', 'CONSTANT', 'x_0']\n","CONSTANT + CONSTANT * x_0\n","['add', 'mul', 'CONSTANT', 'pow', 'add', 'CONSTANT', 'x_0', 'INT+', '3', 'mul', 'CONSTANT', 'x_0']\n","CONSTANT * (CONSTANT + x_0)**3 + CONSTANT * x_0\n","['add', 'mul', 'CONSTANT', 'x_0', 'mul', 'CONSTANT', 'pow', 'add', 'INT-', '1', 'mul', 'CONSTANT', 'x_0', 'INT+', '3']\n","CONSTANT * x_0 + CONSTANT * (-1 + CONSTANT * x_0)**3\n","['add', 'mul', 'CONSTANT', 'pow', 'add', 'CONSTANT', 'mul', 'CONSTANT', 'x_0', 'INT-', '1', 'mul', 'CONSTANT', 'pow', 'add', 'CONSTANT', 'mul', 'CONSTANT', 'x_0', 'INT-', '1']\n","CONSTANT * (CONSTANT + CONSTANT * x_0)**-1 + CONSTANT * (CONSTANT + CONSTANT * x_0)**-1\n","['add', 'mul', 'CONSTANT', 'pow', 'x_0', 'INT+', '2', 'mul', 'CONSTANT', 'x_0']\n","CONSTANT * (x_0)**2 + CONSTANT * x_0\n","['add', 'mul', 'CONSTANT', 'pow', 'add', 'INT-', '1', 'mul', 'CONSTANT', 'x_0', 'INT+', '2', 'add', 'mul', 'CONSTANT', 'x_0', 'mul', 'CONSTANT', 'pow', 'add', 'INT+', '1', 'mul', 'CONSTANT', 'x_0', 'INT+', '3']\n","CONSTANT * (-1 + CONSTANT * x_0)**2 + CONSTANT * x_0 + CONSTANT * (1 + CONSTANT * x_0)**3\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['add', 'CONSTANT', 'mul', 'CONSTANT', 'x_0']\n","CONSTANT + CONSTANT * x_0\n","['add', 'mul', 'CONSTANT', 'pow', 'x_0', 'INT+', '3', 'mul', 'CONSTANT', 'x_0']\n","CONSTANT * (x_0)**3 + CONSTANT * x_0\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['add', 'mul', 'CONSTANT', 'pow', 'add', 'CONSTANT', 'mul', 'CONSTANT', 'x_0', 'INT-', '1', 'mul', 'CONSTANT', 'pow', 'add', 'CONSTANT', 'mul', 'CONSTANT', 'x_0', 'INT-', '1']\n","CONSTANT * (CONSTANT + CONSTANT * x_0)**-1 + CONSTANT * (CONSTANT + CONSTANT * x_0)**-1\n","['add', 'mul', 'CONSTANT', 'x_0', 'mul', 'CONSTANT', 'pow', 'add', 'INT+', '1', 'mul', 'CONSTANT', 'x_0', 'INT+', '3']\n","CONSTANT * x_0 + CONSTANT * (1 + CONSTANT * x_0)**3\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['add', 'CONSTANT', 'mul', 'CONSTANT', 'x_0']\n","CONSTANT + CONSTANT * x_0\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['add', 'CONSTANT', 'mul', 'CONSTANT', 'x_0']\n","CONSTANT + CONSTANT * x_0\n","['add', 'mul', 'CONSTANT', 'pow', 'add', 'INT-', '1', 'mul', 'CONSTANT', 'x_0', 'INT+', '2', 'mul', 'CONSTANT', 'pow', 'add', 'INT-', '1', 'mul', 'CONSTANT', 'x_0', 'INT+', '2']\n","CONSTANT * (-1 + CONSTANT * x_0)**2 + CONSTANT * (-1 + CONSTANT * x_0)**2\n","['add', 'mul', 'CONSTANT', 'x_0', 'mul', 'CONSTANT', 'pow', 'add', 'INT-', '1', 'mul', 'CONSTANT', 'x_0', 'INT+', '3']\n","CONSTANT * x_0 + CONSTANT * (-1 + CONSTANT * x_0)**3\n","['add', 'CONSTANT', 'add', 'mul', 'CONSTANT', 'x_0', 'mul', 'CONSTANT', 'pow', 'x_0', 'INT+', '2']\n","CONSTANT + CONSTANT * x_0 + CONSTANT * (x_0)**2\n","['add', 'mul', 'CONSTANT', 'pow', 'add', 'INT-', '1', 'mul', 'CONSTANT', 'x_0', 'INT+', '3', 'mul', 'CONSTANT', 'pow', 'add', 'INT+', '1', 'mul', 'CONSTANT', 'x_0', 'INT+', '3']\n","CONSTANT * (-1 + CONSTANT * x_0)**3 + CONSTANT * (1 + CONSTANT * x_0)**3\n","['add', 'mul', 'CONSTANT', 'x_0', 'mul', 'CONSTANT', 'pow', 'add', 'INT+', '1', 'mul', 'CONSTANT', 'x_0', 'INT+', '3']\n","CONSTANT * x_0 + CONSTANT * (1 + CONSTANT * x_0)**3\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['add', 'CONSTANT', 'mul', 'CONSTANT', 'x_0']\n","CONSTANT + CONSTANT * x_0\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['add', 'mul', 'CONSTANT', 'x_0', 'mul', 'CONSTANT', 'pow', 'add', 'mul', 'CONSTANT', 'x_0', 'mul', 'CONSTANT', 'pow', 'add', 'CONSTANT', 'mul', 'CONSTANT', 'x_0', 'INT-', '1', 'INT-', '1']\n","CONSTANT * x_0 + CONSTANT * (CONSTANT * x_0 + CONSTANT * (CONSTANT + CONSTANT * x_0)**-1)**-1\n","['add', 'mul', 'CONSTANT', 'pow', 'add', 'INT+', '1', 'mul', 'CONSTANT', 'x_0', 'INT+', '2', 'mul', 'CONSTANT', 'pow', 'add', 'CONSTANT', 'mul', 'CONSTANT', 'x_0', 'INT-', '1']\n","CONSTANT * (1 + CONSTANT * x_0)**2 + CONSTANT * (CONSTANT + CONSTANT * x_0)**-1\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['add', 'mul', 'CONSTANT', 'pow', 'add', 'CONSTANT', 'mul', 'CONSTANT', 'x_0', 'INT-', '1', 'mul', 'CONSTANT', 'pow', 'add', 'CONSTANT', 'mul', 'CONSTANT', 'x_0', 'INT-', '1']\n","CONSTANT * (CONSTANT + CONSTANT * x_0)**-1 + CONSTANT * (CONSTANT + CONSTANT * x_0)**-1\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['add', 'mul', 'CONSTANT', 'x_0', 'mul', 'CONSTANT', 'pow', 'add', 'INT-', '1', 'mul', 'CONSTANT', 'x_0', 'INT+', '3']\n","CONSTANT * x_0 + CONSTANT * (-1 + CONSTANT * x_0)**3\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['add', 'mul', 'CONSTANT', 'x_0', 'mul', 'CONSTANT', 'pow', 'add', 'INT-', '1', 'mul', 'CONSTANT', 'x_0', 'INT+', '2']\n","CONSTANT * x_0 + CONSTANT * (-1 + CONSTANT * x_0)**2\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n","['add', 'mul', 'CONSTANT', 'x_0', 'mul', 'CONSTANT', 'pow', 'add', 'INT-', '1', 'mul', 'CONSTANT', 'x_0', 'INT+', '2']\n","CONSTANT * x_0 + CONSTANT * (-1 + CONSTANT * x_0)**2\n","['mul', 'CONSTANT', 'x_0']\n","CONSTANT * x_0\n"]}]},{"cell_type":"markdown","source":["# Extracting activations from generated samples"],"metadata":{"id":"kBPqvhSMjTT9"}},{"cell_type":"code","source":["from odeformer.model import SymbolicTransformerRegressor\n","dstr = SymbolicTransformerRegressor(from_pretrained=True)\n","model_args = {'beam_size': 50, 'beam_temperature': 0.1}\n","dstr.set_model_args(model_args)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RjoIHqlgoCVI","outputId":"baae5a82-a073-427a-c69a-06bd5672419b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found pretrained model at odeformer.pt\n","Loaded pretrained model\n"]}]},{"cell_type":"code","source":["# Copied from Soumyadeep's notebook\n","\n","layer_outputs = {}\n","\n","# Function to store the output of each layer\n","def hook_fn(module, input, output, layer_name):\n","    layer_outputs[layer_name] = output.detach().cpu() #  detach to avoid unnecessary gradient tracking, and move to store in cpu\n","\n","# Registering hooks for layers in the encoder and decoder\n","def register_hooks(model_part, part_name):\n","    for idx, module in enumerate(model_part.attentions):  # MultiHeadAttention layers\n","        layer_name = f\"{part_name}_attention_{idx}\"\n","        module.register_forward_hook(lambda module, input, output, name=layer_name: hook_fn(module, input, output, name))\n","\n","    for idx, module in enumerate(model_part.ffns):  # FeedForward layers\n","        layer_name = f\"{part_name}_ffn_{idx}\"\n","        module.register_forward_hook(lambda module, input, output, name=layer_name: hook_fn(module, input, output, name))\n","\n","    for idx, module in enumerate(model_part.layer_norm1):  # LayerNorm 1 layers\n","        layer_name = f\"{part_name}_layer_norm1_{idx}\"\n","        module.register_forward_hook(lambda module, input, output, name=layer_name: hook_fn(module, input, output, name))\n","\n","    for idx, module in enumerate(model_part.layer_norm2):  # LayerNorm 2 layers\n","        layer_name = f\"{part_name}_layer_norm2_{idx}\"\n","        module.register_forward_hook(lambda module, input, output, name=layer_name: hook_fn(module, input, output, name))\n","\n","# Registering hooks for the encoder and decoder parts\n","register_hooks(dstr.model.encoder, 'encoder')\n","register_hooks(dstr.model.decoder, 'decoder')"],"metadata":{"id":"uIcGsY4ujXh8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# samples_dir = os.fsencode(samples_path)\n","\n","# for sample in os.listdir(samples_dir):\n","#     sample_name = os.fsdecode(sample)\n","#     # if sample_name.endswith(\".pt\"):\n","#     #     pass\n","#     # Assume that all files in sample are samples saved in the correct way\n","\n","#     sample_path = os.path.join(samples_path, sample_name)\n","#     test_sample = torch.load(sample_path)\n","#     print(f\"[INFO] Loaded sample from {sample_path}\")\n","#     break"],"metadata":{"id":"K2SuX8yeo_PT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Passing data through the model to capture layer outputs\n","# with torch.no_grad():\n","#     dstr.fit(test_sample['times'], test_sample['trajectory'])"],"metadata":{"id":"KWaA6BEao-As"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# encoder_layer_outputs = {}\n","# decoder_layer_outputs = {}\n","# activations = {}\n","\n","# # Now, layer_outputs contains the outputs of the layers\n","# for layer_name, output in layer_outputs.items():\n","#     # print(f\"Layer: {layer_name}, Output Shape: {output.shape}\")\n","#     if 'ffn' in layer_name:\n","#     # Look at ouputs of ffn layers since they come before layer norm?\n","#       print(f'Layer: {layer_name}, Output Shape: {output.shape}')\n","#       if 'encoder' in layer_name:\n","#         encoder_layer_outputs[layer_name] = output\n","#       if 'decoder' in layer_name:\n","#         decoder_layer_outputs[layer_name] = output\n","\n","# activations['encoder'] = encoder_layer_outputs\n","# activations['decoder'] = decoder_layer_outputs\n","# activations['operator_dict'] = test_sample['operator_dict']\n","# activations['feature_dict'] = test_sample['feature_dict']"],"metadata":{"id":"zUUk19GE4VgL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(activations.keys())"],"metadata":{"id":"y7XQhQc97_Wy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test_seed = re.findall(r'\\d+', sample_name)[0]\n","\n","# print(sample_name)\n","# print(test_seed)\n","\n","# activation_filename = f\"activation_{test_seed}.pt\"\n","# activation_filepath = os.path.join(activations_path, activation_filename)\n","\n","# torch.save(activations, activation_filepath)"],"metadata":{"id":"lBD_WQ4P_SnZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Turn the above into a loop over the samples directory\n","\n","os.makedirs(activations_path, exist_ok=True)\n","\n","samples_dir = os.fsencode(samples_path)\n","for sample in os.listdir(samples_dir):\n","  sample_name = os.fsdecode(sample)\n","  sample_path = os.path.join(samples_path, sample_name)\n","  test_sample = torch.load(sample_path)\n","  print(f\"[INFO] Loaded sample from {sample_path}\")\n","  with torch.no_grad():\n","    dstr.fit(test_sample['times'], test_sample['trajectory'])\n","  encoder_layer_outputs = {}\n","  decoder_layer_outputs = {}\n","  activations = {}\n","\n","  for layer_name, output in layer_outputs.items():\n","      if 'ffn' in layer_name:\n","      # Look at ouputs of ffn layers since they come before layer norm?\n","        if 'encoder' in layer_name:\n","          encoder_layer_outputs[layer_name] = output\n","        if 'decoder' in layer_name:\n","          decoder_layer_outputs[layer_name] = output\n","\n","  activations['encoder'] = encoder_layer_outputs\n","  activations['decoder'] = decoder_layer_outputs\n","  activations['operator_dict'] = test_sample['operator_dict']\n","  activations['feature_dict'] = test_sample['feature_dict']\n","\n","  test_seed = re.findall(r'\\d+', sample_name)[0]\n","  activation_filename = f\"activation_{test_seed}.pt\"\n","  activation_filepath = os.path.join(activations_path, activation_filename)\n","  torch.save(activations, activation_filepath)\n","  print(f\"[INFO] Saved activations to {activation_filepath}\")"],"metadata":{"id":"_rKvEa0KMC9B","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ee68b07c-1408-4f91-f873-20f909f66d0e","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] Loaded sample from /content/drive/MyDrive/aisc/samples/sample_669991378.pt\n","[INFO] Saved activations to /content/drive/MyDrive/aisc/activations/activation_669991378.pt\n","[INFO] Loaded sample from /content/drive/MyDrive/aisc/samples/sample_429389014.pt\n","[INFO] Saved activations to /content/drive/MyDrive/aisc/activations/activation_429389014.pt\n","[INFO] Loaded sample from /content/drive/MyDrive/aisc/samples/sample_249467210.pt\n","[INFO] Saved activations to /content/drive/MyDrive/aisc/activations/activation_249467210.pt\n","[INFO] Loaded sample from /content/drive/MyDrive/aisc/samples/sample_898717130.pt\n","[INFO] Saved activations to /content/drive/MyDrive/aisc/activations/activation_898717130.pt\n","[INFO] Loaded sample from /content/drive/MyDrive/aisc/samples/sample_498972759.pt\n","[INFO] Saved activations to /content/drive/MyDrive/aisc/activations/activation_498972759.pt\n","[INFO] Loaded sample from /content/drive/MyDrive/aisc/samples/sample_359525748.pt\n","[INFO] Saved activations to /content/drive/MyDrive/aisc/activations/activation_359525748.pt\n","[INFO] Loaded sample from /content/drive/MyDrive/aisc/samples/sample_434285667.pt\n","[INFO] Saved activations to /content/drive/MyDrive/aisc/activations/activation_434285667.pt\n","[INFO] Loaded sample from /content/drive/MyDrive/aisc/samples/sample_613608295.pt\n","[INFO] Saved activations to /content/drive/MyDrive/aisc/activations/activation_613608295.pt\n","[INFO] Loaded sample from /content/drive/MyDrive/aisc/samples/sample_893664919.pt\n","[INFO] Saved activations to /content/drive/MyDrive/aisc/activations/activation_893664919.pt\n","[INFO] Loaded sample from /content/drive/MyDrive/aisc/samples/sample_648061058.pt\n","[INFO] Saved activations to /content/drive/MyDrive/aisc/activations/activation_648061058.pt\n"]}]},{"cell_type":"code","source":["# print(len(encoder_layer_outputs))\n","# print(len(decoder_layer_outputs))\n","# # These appear to be +1 to how many there should be. I guess the embedding layer norm is counted?"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e88H8ofX221B","outputId":"c616a668-eb9e-40e3-fdd3-b7bdbdbca9f1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["5\n","13\n"]}]},{"cell_type":"code","source":["# print(dstr_encoder)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4tMZxoGXWUNv","outputId":"59ff7778-d79d-45fa-8e70-6c9c79dea35e","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["TransformerModel(\n","  (layer_norm_emb): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","  (attentions): ModuleList(\n","    (0-3): 4 x MultiHeadAttention(\n","      (q_lin): Linear(in_features=256, out_features=256, bias=True)\n","      (k_lin): Linear(in_features=256, out_features=256, bias=True)\n","      (v_lin): Linear(in_features=256, out_features=256, bias=True)\n","      (out_lin): Linear(in_features=256, out_features=256, bias=True)\n","    )\n","  )\n","  (layer_norm1): ModuleList(\n","    (0-3): 4 x LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","  )\n","  (ffns): ModuleList(\n","    (0-3): 4 x TransformerFFN(\n","      (midlin): ModuleList()\n","      (lin1): Linear(in_features=256, out_features=1024, bias=True)\n","      (lin2): Linear(in_features=1024, out_features=256, bias=True)\n","    )\n","  )\n","  (layer_norm2): ModuleList(\n","    (0-3): 4 x LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","  )\n",")\n"]}]},{"cell_type":"code","source":["# print(dstr_decoder)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cYn7B2WsTZJ2","outputId":"683a3bb2-d52b-467c-8bba-62f17e5fdae6","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["TransformerModel(\n","  (position_embeddings): Embedding(4096, 512)\n","  (embeddings): Embedding(10293, 512, padding_idx=82)\n","  (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","  (attentions): ModuleList(\n","    (0-11): 12 x MultiHeadAttention(\n","      (q_lin): Linear(in_features=512, out_features=512, bias=True)\n","      (k_lin): Linear(in_features=512, out_features=512, bias=True)\n","      (v_lin): Linear(in_features=512, out_features=512, bias=True)\n","      (out_lin): Linear(in_features=512, out_features=512, bias=True)\n","    )\n","  )\n","  (layer_norm1): ModuleList(\n","    (0-11): 12 x LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","  )\n","  (ffns): ModuleList(\n","    (0-11): 12 x TransformerFFN(\n","      (midlin): ModuleList()\n","      (lin1): Linear(in_features=512, out_features=2048, bias=True)\n","      (lin2): Linear(in_features=2048, out_features=512, bias=True)\n","    )\n","  )\n","  (layer_norm2): ModuleList(\n","    (0-11): 12 x LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","  )\n","  (layer_norm15): ModuleList(\n","    (0-11): 12 x LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","  )\n","  (encoder_attn): ModuleList(\n","    (0-11): 12 x MultiHeadAttention(\n","      (q_lin): Linear(in_features=512, out_features=512, bias=True)\n","      (k_lin): Linear(in_features=256, out_features=512, bias=True)\n","      (v_lin): Linear(in_features=256, out_features=512, bias=True)\n","      (out_lin): Linear(in_features=512, out_features=512, bias=True)\n","    )\n","  )\n","  (proj): Linear(in_features=512, out_features=10293, bias=True)\n",")\n"]}]}]}
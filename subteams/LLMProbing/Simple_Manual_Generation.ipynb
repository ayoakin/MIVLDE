{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RjfcoooM8Y_3",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0465945-f557-4706-8d05-204757d7132c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/odeformer'...\n",
            "remote: Enumerating objects: 1984, done.\u001b[K\n",
            "remote: Counting objects: 100% (332/332), done.\u001b[K\n",
            "remote: Compressing objects: 100% (138/138), done.\u001b[K\n",
            "remote: Total 1984 (delta 200), reused 308 (delta 191), pack-reused 1652 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1984/1984), 40.82 MiB | 16.44 MiB/s, done.\n",
            "Resolving deltas: 100% (1436/1436), done.\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.4.1 which is incompatible.\n",
            "torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import scipy.integrate\n",
        "import sympy as sp\n",
        "import pickle\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "repo_path = Path(\"/content/odeformer\")\n",
        "if not repo_path.exists():\n",
        "    !git clone https://github.com/sdascoli/odeformer.git {repo_path}\n",
        "\n",
        "!pip install --quiet numexpr sympy==1.11.1 matplotlib numpy pandas requests scikit-learn scipy seaborn setproctitle torch tqdm wandb gdown regex\n",
        "import torch\n",
        "sys.path.append(\"/content/odeformer\")\n",
        "sys.path.append(\"/content/odeformer/envs\")\n",
        "\n",
        "sys.path.append(\"/content/odeformer/\")\n",
        "sys.path.append(\"/content/odeformer/odeformer\")\n",
        "sys.path.append(\"/content/odeformer/odeformer/envs\")\n",
        "#Ignore dependency issue with torchaudio and torchvision."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#Need to give access to drive\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4wpkvTERKTB",
        "outputId": "4a5a12ab-93a1-4098-efe7-0ee9052b7a36",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Need to create the folder \"aisc\" in MyDrive. Will create the sub folders if they don't exist\n",
        "samples_path = '/content/drive/MyDrive/aisc/samples_manual_0'\n",
        "activations_path = '/content/drive/MyDrive/aisc/activations_manual_0'"
      ],
      "metadata": {
        "id": "K0QvwcFbTX_k"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate Samples, Pickle and save To drive**"
      ],
      "metadata": {
        "id": "LO_J25mursRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#In order to make expressions for equations easier to read\n",
        "def clean_expression(expression):\n",
        "    cleaned = expression.replace('--', '')\n",
        "    cleaned = cleaned.replace(' -', '-')\n",
        "    cleaned = cleaned.replace('- ', '-')\n",
        "    return cleaned\n"
      ],
      "metadata": {
        "id": "Ja-5fY5Y_cCa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_exp_decay_dictionaries(t, c_values, a_values):\n",
        "\n",
        "    manual_samples = []\n",
        "\n",
        "    for c_val in c_values:\n",
        "        for a_val in a_values:\n",
        "            trajectory = (c_val * np.exp(-a_val * t)).reshape(-1, 1)\n",
        "            sample_dict = {\n",
        "                'times': t,\n",
        "                'trajectory': trajectory,\n",
        "                'a': float(a_val),  # Convert to float for better serialization\n",
        "                'c': float(c_val)   # Convert to float for better serialization\n",
        "                ,'feature_dict': {\"exponential_decay\": 1, \"Quadratic\": 0}\n",
        "                ,'expression': clean_expression(f\"{c_val} * np.exp(-{a_val} * t)\")\n",
        "            }\n",
        "            manual_samples.append(sample_dict)\n",
        "\n",
        "    return manual_samples"
      ],
      "metadata": {
        "id": "Ud3zFRxW8jPH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_quadratic_dictionaries(t, c_values, t0_values):\n",
        "\n",
        "    manual_samples = []\n",
        "\n",
        "    for c_val in c_values:\n",
        "        for t0_val in t0_values:\n",
        "            trajectory = (c_val / (t0_val - t)).reshape(-1, 1)\n",
        "            sample_dict = {\n",
        "                'times': t,\n",
        "                'trajectory': trajectory,\n",
        "                'a': float(t0_val),  # Convert to float for better serialization\n",
        "                'c': float(c_val)   # Convert to float for better serialization\n",
        "                ,'feature_dict': {\"exponential_decay\": 0, \"Quadratic\": 1}\n",
        "                ,'expression': clean_expression(f\"{c_val} / ({t0_val} - t)\")\n",
        "            }\n",
        "            manual_samples.append(sample_dict)\n",
        "\n",
        "    return manual_samples"
      ],
      "metadata": {
        "id": "AV3PCy8t8xRP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify time series and which constants to loop through.\n",
        "t=np.linspace(1, 10, 50)\n",
        "\n",
        "#c = np.linspace(-10,10, 21)\n",
        "c = np.linspace(-10,10, 2)\n",
        "\n",
        "#a = np.linspace(-10,10, 21)\n",
        "a = np.linspace(-10,10, 2)\n",
        "\n",
        "manual_samples = generate_exp_decay_dictionaries(t, c, a)\n",
        "\n",
        "#c = np.linspace(-10,10, 21)\n",
        "c = np.linspace(-10,10, 2)\n",
        "\n",
        "#t0 = np.linspace(10.1, 100, 21)\n",
        "t0 = np.linspace(10.1, 100, 2)\n",
        "\n",
        "manual_samples = manual_samples + generate_quadratic_dictionaries(t, c, t0)"
      ],
      "metadata": {
        "id": "16sad8L44RDh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "manual_samples[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ULKZ5jmW6NJw",
        "outputId": "e8939346-abf1-4985-f323-2a97d9b282cd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'times': array([ 1.        ,  1.18367347,  1.36734694,  1.55102041,  1.73469388,\n",
              "         1.91836735,  2.10204082,  2.28571429,  2.46938776,  2.65306122,\n",
              "         2.83673469,  3.02040816,  3.20408163,  3.3877551 ,  3.57142857,\n",
              "         3.75510204,  3.93877551,  4.12244898,  4.30612245,  4.48979592,\n",
              "         4.67346939,  4.85714286,  5.04081633,  5.2244898 ,  5.40816327,\n",
              "         5.59183673,  5.7755102 ,  5.95918367,  6.14285714,  6.32653061,\n",
              "         6.51020408,  6.69387755,  6.87755102,  7.06122449,  7.24489796,\n",
              "         7.42857143,  7.6122449 ,  7.79591837,  7.97959184,  8.16326531,\n",
              "         8.34693878,  8.53061224,  8.71428571,  8.89795918,  9.08163265,\n",
              "         9.26530612,  9.44897959,  9.63265306,  9.81632653, 10.        ]),\n",
              " 'trajectory': array([[-2.20264658e+05],\n",
              "        [-1.38238356e+06],\n",
              "        [-8.67585537e+06],\n",
              "        [-5.44497695e+07],\n",
              "        [-3.41727389e+08],\n",
              "        [-2.14468508e+09],\n",
              "        [-1.34600686e+10],\n",
              "        [-8.44755474e+10],\n",
              "        [-5.30169521e+11],\n",
              "        [-3.32735010e+12],\n",
              "        [-2.08824881e+13],\n",
              "        [-1.31058739e+14],\n",
              "        [-8.22526173e+14],\n",
              "        [-5.16218386e+15],\n",
              "        [-3.23979261e+16],\n",
              "        [-2.03329762e+17],\n",
              "        [-1.27609996e+18],\n",
              "        [-8.00881824e+18],\n",
              "        [-5.02634367e+19],\n",
              "        [-3.15453915e+20],\n",
              "        [-1.97979245e+21],\n",
              "        [-1.24252005e+22],\n",
              "        [-7.79807035e+22],\n",
              "        [-4.89407805e+23],\n",
              "        [-3.07152910e+24],\n",
              "        [-1.92769524e+25],\n",
              "        [-1.20982378e+26],\n",
              "        [-7.59286818e+26],\n",
              "        [-4.76529293e+27],\n",
              "        [-2.99070340e+28],\n",
              "        [-1.87696895e+29],\n",
              "        [-1.17798790e+30],\n",
              "        [-7.39306580e+30],\n",
              "        [-4.63989672e+31],\n",
              "        [-2.91200460e+32],\n",
              "        [-1.82757748e+33],\n",
              "        [-1.14698976e+34],\n",
              "        [-7.19852112e+34],\n",
              "        [-4.51780025e+35],\n",
              "        [-2.83537671e+36],\n",
              "        [-1.77948573e+37],\n",
              "        [-1.11680732e+38],\n",
              "        [-7.00909578e+38],\n",
              "        [-4.39891669e+39],\n",
              "        [-2.76076524e+40],\n",
              "        [-1.73265949e+41],\n",
              "        [-1.08741912e+42],\n",
              "        [-6.82465506e+42],\n",
              "        [-4.28316148e+43],\n",
              "        [-2.68811714e+44]]),\n",
              " 'a': -10.0,\n",
              " 'c': -10.0,\n",
              " 'feature_dict': {'exponential_decay': 1, 'Quadratic': 0},\n",
              " 'expression': '-10.0 * np.exp(10.0 * t)'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#index to name the different samples\n",
        "i =0\n",
        "for sample in manual_samples:\n",
        "    sample_filename = f\"sample_man_{i}.pt\"\n",
        "    sample_filepath = os.path.join(samples_path, sample_filename)\n",
        "    os.makedirs(os.path.dirname(sample_filepath), exist_ok=True)\n",
        "    # Save file on drive using pickle\n",
        "    with open(sample_filepath, 'wb') as f:\n",
        "      pickle.dump(sample, f)\n",
        "    print(f\"[INFO] Saved to {sample_filepath}\")\n",
        "    i+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AngE3b4HE3N2",
        "outputId": "3acc0edd-900a-4a96-8446-42320303ad8e",
        "collapsed": true
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Saved to /content/drive/MyDrive/aisc/samples_manual_0/sample_man_0.pt\n",
            "[INFO] Saved to /content/drive/MyDrive/aisc/samples_manual_0/sample_man_1.pt\n",
            "[INFO] Saved to /content/drive/MyDrive/aisc/samples_manual_0/sample_man_2.pt\n",
            "[INFO] Saved to /content/drive/MyDrive/aisc/samples_manual_0/sample_man_3.pt\n",
            "[INFO] Saved to /content/drive/MyDrive/aisc/samples_manual_0/sample_man_4.pt\n",
            "[INFO] Saved to /content/drive/MyDrive/aisc/samples_manual_0/sample_man_5.pt\n",
            "[INFO] Saved to /content/drive/MyDrive/aisc/samples_manual_0/sample_man_6.pt\n",
            "[INFO] Saved to /content/drive/MyDrive/aisc/samples_manual_0/sample_man_7.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load samples from drive, run them through network to generate activations, pickle the activations and save to drive**"
      ],
      "metadata": {
        "id": "P4_rHp-1rjr8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "b0Oqll48Btnk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "292382dc-0683-4e6b-c420-91e069ace4e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading pretrained model and saving to odeformer.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1L_UZ0qgrBVkRuhg5j3BQoGxlvMk_Pm1W\n",
            "From (redirected): https://drive.google.com/uc?id=1L_UZ0qgrBVkRuhg5j3BQoGxlvMk_Pm1W&confirm=t&uuid=d2550677-8ac2-42fd-b616-0d79f76d2095\n",
            "To: /content/odeformer.pt\n",
            "100%|██████████| 465M/465M [00:13<00:00, 35.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained model\n"
          ]
        }
      ],
      "source": [
        "from odeformer.model import SymbolicTransformerRegressor\n",
        "dstr = SymbolicTransformerRegressor(from_pretrained=True)\n",
        "model_args = {'beam_size': 50, 'beam_temperature': 0.1}\n",
        "dstr.set_model_args(model_args)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer_outputs = {}\n",
        "\n",
        "# Function to store the output of each layer\n",
        "def hook_fn(module, input, output, layer_name):\n",
        "    layer_outputs[layer_name] = output.detach().cpu() #  detach to avoid unnecessary gradient tracking, and move to store in cpu\n",
        "\n",
        "# Registering hooks for layers in the encoder and decoder\n",
        "def register_hooks(model_part, part_name):\n",
        "    for idx, module in enumerate(model_part.attentions):  # MultiHeadAttention layers\n",
        "        layer_name = f\"{part_name}_attention_{idx}\"\n",
        "        module.register_forward_hook(lambda module, input, output, name=layer_name: hook_fn(module, input, output, name))\n",
        "\n",
        "    for idx, module in enumerate(model_part.ffns):  # FeedForward layers\n",
        "        layer_name = f\"{part_name}_ffn_{idx}\"\n",
        "        module.register_forward_hook(lambda module, input, output, name=layer_name: hook_fn(module, input, output, name))\n",
        "\n",
        "    for idx, module in enumerate(model_part.layer_norm1):  # LayerNorm 1 layers\n",
        "        layer_name = f\"{part_name}_layer_norm1_{idx}\"\n",
        "        module.register_forward_hook(lambda module, input, output, name=layer_name: hook_fn(module, input, output, name))\n",
        "\n",
        "    for idx, module in enumerate(model_part.layer_norm2):  # LayerNorm 2 layers\n",
        "        layer_name = f\"{part_name}_layer_norm2_{idx}\"\n",
        "        module.register_forward_hook(lambda module, input, output, name=layer_name: hook_fn(module, input, output, name))\n",
        "\n",
        "# Registering hooks for the encoder and decoder parts\n",
        "register_hooks(dstr.model.encoder, 'encoder')\n",
        "register_hooks(dstr.model.decoder, 'decoder')"
      ],
      "metadata": {
        "id": "hJ8EuIYs2c38"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(activations_path, exist_ok=True)\n",
        "\n",
        "samples_dir = os.fsencode(samples_path)\n",
        "for sample in os.listdir(samples_dir):\n",
        "  sample_name = os.fsdecode(sample)\n",
        "  sample_path = os.path.join(samples_path, sample_name)\n",
        "  with open(sample_path, 'rb') as f:\n",
        "    test_sample = pickle.load(f)\n",
        "  print(f\"[INFO] Loaded sample from {sample_path}\")\n",
        "  with torch.no_grad():\n",
        "    dstr.fit(test_sample['times'], test_sample['trajectory'])\n",
        "  encoder_layer_outputs = {}\n",
        "  decoder_layer_outputs = {}\n",
        "  activations = {}\n",
        "\n",
        "  for layer_name, output in layer_outputs.items():\n",
        "      if 'ffn' in layer_name:\n",
        "      # Look at ouputs of ffn layers since they come before layer norm.\n",
        "      # Include the entire Residual stream (output[0:1, :, :] to grab first beam)\n",
        "        if 'encoder' in layer_name:\n",
        "          encoder_layer_outputs[layer_name] = output\n",
        "        if 'decoder' in layer_name:\n",
        "          decoder_layer_outputs[layer_name] = output\n",
        "  #Save both encoder and decoder activations\n",
        "  activations['encoder'] = encoder_layer_outputs\n",
        "  activations['decoder'] = decoder_layer_outputs\n",
        "  try:\n",
        "    activations['operator_dict'] = test_sample['operator_dict']\n",
        "  except KeyError:\n",
        "    pass\n",
        "  activations['feature_dict'] = test_sample['feature_dict']\n",
        "\n",
        "  test_seed = re.findall(r'\\d+', sample_name)[0]\n",
        "  activation_filename = f\"activation_{test_seed}.pt\"\n",
        "  activation_filepath = os.path.join(activations_path, activation_filename)\n",
        "  with open(activation_filepath, 'wb') as f:\n",
        "    pickle.dump(activations, f)\n",
        "  print(f\"[INFO] Saved activations to {activation_filepath}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iGJpB3d2i65",
        "outputId": "83a7e830-cf08-41af-8c4e-106c483863b8",
        "collapsed": true
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Loaded sample from /content/drive/MyDrive/aisc/samples_manual_0/sample_man_0.pt\n",
            "[INFO] Saved activations to /content/drive/MyDrive/aisc/activations_manual_0/activation_0.pt\n",
            "[INFO] Loaded sample from /content/drive/MyDrive/aisc/samples_manual_0/sample_man_1.pt\n",
            "[INFO] Saved activations to /content/drive/MyDrive/aisc/activations_manual_0/activation_1.pt\n",
            "[INFO] Loaded sample from /content/drive/MyDrive/aisc/samples_manual_0/sample_man_2.pt\n",
            "[INFO] Saved activations to /content/drive/MyDrive/aisc/activations_manual_0/activation_2.pt\n",
            "[INFO] Loaded sample from /content/drive/MyDrive/aisc/samples_manual_0/sample_man_3.pt\n",
            "[INFO] Saved activations to /content/drive/MyDrive/aisc/activations_manual_0/activation_3.pt\n",
            "[INFO] Loaded sample from /content/drive/MyDrive/aisc/samples_manual_0/sample_man_4.pt\n",
            "[INFO] Saved activations to /content/drive/MyDrive/aisc/activations_manual_0/activation_4.pt\n",
            "[INFO] Loaded sample from /content/drive/MyDrive/aisc/samples_manual_0/sample_man_5.pt\n",
            "[INFO] Saved activations to /content/drive/MyDrive/aisc/activations_manual_0/activation_5.pt\n",
            "[INFO] Loaded sample from /content/drive/MyDrive/aisc/samples_manual_0/sample_man_6.pt\n",
            "[INFO] Saved activations to /content/drive/MyDrive/aisc/activations_manual_0/activation_6.pt\n",
            "[INFO] Loaded sample from /content/drive/MyDrive/aisc/samples_manual_0/sample_man_7.pt\n",
            "[INFO] Saved activations to /content/drive/MyDrive/aisc/activations_manual_0/activation_7.pt\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "odeformer-wsl",
      "language": "python",
      "name": "odeformer-wsl"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6e055114",
      "metadata": {
        "cell_marker": "\"\"\"",
        "id": "6e055114"
      },
      "source": [
        "# Time Series Transformer on Synthetic Function Data\n",
        "\n",
        "This script trains a Time Series Transformer on a synthetic dataset where each time series is generated as as a function of t\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f7e9ceb9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7e9ceb9",
        "outputId": "8e830cf1-ca7f-4781-eda9-b408f6369f92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/484.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m368.6/484.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.9/484.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hImports complete.\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "\n",
        "!pip install -q transformers datasets evaluate accelerate gluonts ujson\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from functools import lru_cache, partial\n",
        "\n",
        "# Hugging Face Transformers for time series\n",
        "from transformers import (\n",
        "    TimeSeriesTransformerConfig,\n",
        "    TimeSeriesTransformerForPrediction,\n",
        ")\n",
        "\n",
        "# GluonTS imports for time features and transforms\n",
        "from gluonts.time_feature import time_features_from_frequency_str, get_lags_for_frequency\n",
        "from gluonts.dataset.field_names import FieldName\n",
        "from gluonts.transform import (\n",
        "    Chain,\n",
        "    RemoveFields,\n",
        "    AsNumpyArray,\n",
        "    AddObservedValuesIndicator,\n",
        "    AddTimeFeatures,\n",
        "    AddAgeFeature,\n",
        "    VstackFeatures,\n",
        "    RenameFields,\n",
        "    InstanceSplitter,\n",
        ")\n",
        "from gluonts.transform.sampler import ExpectedNumInstanceSampler, TestSplitSampler\n",
        "\n",
        "# Just in case\n",
        "from datasets import Dataset\n",
        "\n",
        "print(\"Imports complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Generation - we define our function here"
      ],
      "metadata": {
        "id": "1ucDfQYpDRUp"
      },
      "id": "1ucDfQYpDRUp"
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate training and validation data\n",
        "\n",
        "# ----- Parameters -----\n",
        "num_series = 200         # Number of time series (fragments) to simulate\n",
        "prediction_length = 50  # Forecast horizon: number of time steps to predict\n",
        "train_length = 250      # Number of time steps used for training (historical data)\n",
        "total_length = train_length + prediction_length  # Total length of each series\n",
        "\n",
        "# Define a base date for the start of the time series\n",
        "base_date = pd.to_datetime(\"2020-01-01\")\n",
        "\n",
        "# Lists to store the datasets\n",
        "train_dataset = []\n",
        "validation_dataset = []\n",
        "\n",
        "# Generate multiple time series fragments from the same function\n",
        "for i in range(num_series):\n",
        "    # Each series gets a different start date (e.g., day i)\n",
        "    start_date = base_date + pd.Timedelta(days=i)\n",
        "    start = pd.Period(start_date, freq=\"D\")  # Using daily frequency for simplicity\n",
        "\n",
        "    # Create a time vector for this series\n",
        "    t_vals = np.arange(total_length)  # 0, 1, 2, ..., total_length-1\n",
        "\n",
        "    '''\n",
        "    This is the function we predict!! Input it here\n",
        "    Ex. values = np.exp(-t_vals)\n",
        "    '''\n",
        "    values = np.exp(-t_vals)\n",
        "\n",
        "\n",
        "    # Training series: use only the historical part (first train_length points)\n",
        "    train_series = {\n",
        "        \"start\": start,\n",
        "        \"target\": values[:train_length].tolist(),\n",
        "    }\n",
        "\n",
        "    # Validation series: use the full series (historical data + forecast horizon)\n",
        "    # The last 'prediction_length' points serve as the ground truth for evaluation.\n",
        "    full_series = {\n",
        "        \"start\": start,\n",
        "        \"target\": values.tolist(),\n",
        "    }\n",
        "\n",
        "    train_dataset.append(train_series)\n",
        "    validation_dataset.append(full_series)\n",
        "\n",
        "# Quick summary\n",
        "print(\"Number of training series:\", len(train_dataset))\n",
        "print(\"Length of each training series:\", len(train_dataset[0][\"target\"]))\n",
        "print(\"Number of validation series:\", len(validation_dataset))\n",
        "print(\"Length of each validation series:\", len(validation_dataset[0][\"target\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbC6EIY5DTPK",
        "outputId": "c5d7bc02-cc33-4318-fe26-51010eb48436"
      },
      "id": "kbC6EIY5DTPK",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training series: 200\n",
            "Length of each training series: 250\n",
            "Number of validation series: 200\n",
            "Length of each validation series: 300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assert the validation dataset is the length of the training dataset + prediction length\n",
        "for idx in range(num_series):\n",
        "  assert len((train_dataset[idx]['target'])) + prediction_length == len(validation_dataset[idx]['target'])"
      ],
      "metadata": {
        "id": "KtnC5u_vLTAx"
      },
      "id": "KtnC5u_vLTAx",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a dataset, alongside its corresponding validation dataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "idx = int(input(\"Index: \"))\n",
        "\n",
        "figure, axes = plt.subplots()\n",
        "print(f\"Starting time: {train_dataset[idx]['start']}\")\n",
        "axes.plot(train_dataset[idx][\"target\"], color=\"blue\")\n",
        "axes.plot(validation_dataset[idx][\"target\"], color=\"red\", alpha=0.5)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "EmpaIlwmL9Gp",
        "outputId": "69ec9f17-ef5c-4f96-d80b-8d54269a2d19"
      },
      "id": "EmpaIlwmL9Gp",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index: 55\n",
            "Starting time: 2020-02-25\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create our training and test split\n",
        "\n",
        "import random\n",
        "\n",
        "# Shuffle the dataset to randomize the order of time series\n",
        "random.shuffle(train_dataset)\n",
        "\n",
        "# Then split into train and test\n",
        "train_split = train_dataset[:100]\n",
        "test_split = train_dataset[100:200]\n",
        "\n",
        "# Assign series id\n",
        "for i in range(len(train_split)):\n",
        "  train_split[i]['feat_static_cat'] = [i]\n",
        "  test_split[i]['feat_static_cat'] = [i]\n"
      ],
      "metadata": {
        "id": "nIFeZkyhMVZ3"
      },
      "id": "nIFeZkyhMVZ3",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gather additional features (lag/time) - time may not be necessary for function extrapolation (but may be helpful to have regardless!)\n",
        "\n",
        "import pandas as pd\n",
        "from gluonts.time_feature import get_lags_for_frequency, time_features_from_frequency_str\n",
        "\n",
        "# Define the frequency as daily (\"D\")\n",
        "freq = \"D\"\n",
        "\n",
        "# Generate the lags sequence for daily data.\n",
        "# This will automatically choose appropriate lags (e.g., 1 day, 7 days, etc.).\n",
        "lags_sequence = get_lags_for_frequency(freq)\n",
        "print(\"Lags sequence for daily frequency:\", lags_sequence)\n",
        "\n",
        "# Generate time features for daily frequency.\n",
        "# Typical features include \"day of week\", \"day of month\", etc.\n",
        "time_features = time_features_from_frequency_str(freq)\n",
        "print(\"Time features for daily frequency:\", time_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LW2XWynfPj_N",
        "outputId": "efb299cf-0b47-41ed-c458-939a8de5c960"
      },
      "id": "LW2XWynfPj_N",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lags sequence for daily frequency: [1, 2, 3, 4, 5, 6, 7, 8, 13, 14, 15, 20, 21, 22, 27, 28, 29, 30, 31, 56, 84, 363, 364, 365, 727, 728, 729, 1091, 1092, 1093]\n",
            "Time features for daily frequency: [<function day_of_week at 0x7daac43c85e0>, <function day_of_month at 0x7daac43c8720>, <function day_of_year at 0x7daac43c8860>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Instantiation"
      ],
      "metadata": {
        "id": "gdRiHMhMP_6X"
      },
      "id": "gdRiHMhMP_6X"
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure our model\n",
        "\n",
        "from transformers import TimeSeriesTransformerConfig, TimeSeriesTransformerForPrediction\n",
        "\n",
        "# Assumptions:\n",
        "# - 'lags_sequence' has been computed in a previous cell using get_lags_for_frequency(\"D\")\n",
        "# - We have a prediction horizon of 50 time steps and a context window of 100 time steps.\n",
        "# - We include a static categorical feature (e.g., series id) for our training set of 100 series.\n",
        "\n",
        "prediction_length = 50\n",
        "context_length = prediction_length * 2  # e.g., 100 time steps\n",
        "\n",
        "# Add in our time features\n",
        "num_time_features = 4\n",
        "\n",
        "# We include one static categorical feature (the series id). In our training split we have 100 series.\n",
        "num_static_categorical_features = 1\n",
        "cardinality = [100]           # 100 unique series ids in our training split.\n",
        "embedding_dimension = [3]     # Example embedding size for the static categorical feature.\n",
        "\n",
        "# Create the configuration.\n",
        "config = TimeSeriesTransformerConfig(\n",
        "    prediction_length=prediction_length,\n",
        "    context_length=context_length,\n",
        "    lags_sequence=lags_sequence,  # Previously computed for daily frequency\n",
        "    num_time_features=num_time_features,\n",
        "    num_static_categorical_features=num_static_categorical_features,\n",
        "    cardinality=cardinality,\n",
        "    embedding_dimension=embedding_dimension,\n",
        "    encoder_layers=2,    # You can adjust this as needed.\n",
        "    decoder_layers=2,    # You can adjust this as needed.\n",
        "    d_model=32,          # The hidden dimension size.\n",
        ")\n",
        "\n",
        "# Instantiate the model using the configuration.\n",
        "model = TimeSeriesTransformerForPrediction(config)\n",
        "print(\"Model configured with:\")\n",
        "print(config)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfNue4t7P9X8",
        "outputId": "cf76a9e2-752f-42fb-d3eb-c1be45e6de19"
      },
      "id": "LfNue4t7P9X8",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model configured with:\n",
            "TimeSeriesTransformerConfig {\n",
            "  \"_attn_implementation_autoset\": true,\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"cardinality\": [\n",
            "    100\n",
            "  ],\n",
            "  \"context_length\": 100,\n",
            "  \"d_model\": 32,\n",
            "  \"decoder_attention_heads\": 2,\n",
            "  \"decoder_ffn_dim\": 32,\n",
            "  \"decoder_layerdrop\": 0.1,\n",
            "  \"decoder_layers\": 2,\n",
            "  \"distribution_output\": \"student_t\",\n",
            "  \"dropout\": 0.1,\n",
            "  \"embedding_dimension\": [\n",
            "    3\n",
            "  ],\n",
            "  \"encoder_attention_heads\": 2,\n",
            "  \"encoder_ffn_dim\": 32,\n",
            "  \"encoder_layerdrop\": 0.1,\n",
            "  \"encoder_layers\": 2,\n",
            "  \"feature_size\": 39,\n",
            "  \"init_std\": 0.02,\n",
            "  \"input_size\": 1,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"lags_sequence\": [\n",
            "    1,\n",
            "    2,\n",
            "    3,\n",
            "    4,\n",
            "    5,\n",
            "    6,\n",
            "    7,\n",
            "    8,\n",
            "    13,\n",
            "    14,\n",
            "    15,\n",
            "    20,\n",
            "    21,\n",
            "    22,\n",
            "    27,\n",
            "    28,\n",
            "    29,\n",
            "    30,\n",
            "    31,\n",
            "    56,\n",
            "    84,\n",
            "    363,\n",
            "    364,\n",
            "    365,\n",
            "    727,\n",
            "    728,\n",
            "    729,\n",
            "    1091,\n",
            "    1092,\n",
            "    1093\n",
            "  ],\n",
            "  \"loss\": \"nll\",\n",
            "  \"model_type\": \"time_series_transformer\",\n",
            "  \"num_dynamic_real_features\": 0,\n",
            "  \"num_parallel_samples\": 100,\n",
            "  \"num_static_categorical_features\": 1,\n",
            "  \"num_static_real_features\": 0,\n",
            "  \"num_time_features\": 4,\n",
            "  \"prediction_length\": 50,\n",
            "  \"scaling\": \"mean\",\n",
            "  \"transformers_version\": \"4.48.3\",\n",
            "  \"use_cache\": true\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution output of our model is student t\n",
        "model.config.distribution_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LhZiT1tvQm4j",
        "outputId": "32cb0eac-2db4-41f2-96e6-4a24dda45bd6"
      },
      "id": "LhZiT1tvQm4j",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'student_t'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define our transformations (in accordance w/ HuggingFace implementation)\n",
        "from gluonts.time_feature import (\n",
        "    time_features_from_frequency_str,\n",
        "    TimeFeature,\n",
        "    get_lags_for_frequency,\n",
        ")\n",
        "from gluonts.dataset.field_names import FieldName\n",
        "from gluonts.transform import (\n",
        "    AddAgeFeature,\n",
        "    AddObservedValuesIndicator,\n",
        "    AddTimeFeatures,\n",
        "    AsNumpyArray,\n",
        "    Chain,\n",
        "    ExpectedNumInstanceSampler,\n",
        "    InstanceSplitter,\n",
        "    RemoveFields,\n",
        "    SelectFields,\n",
        "    SetField,\n",
        "    TestSplitSampler,\n",
        "    Transformation,\n",
        "    ValidationSplitSampler,\n",
        "    VstackFeatures,\n",
        "    RenameFields,\n",
        ")"
      ],
      "metadata": {
        "id": "LAJ-NfhxQxWH"
      },
      "id": "LAJ-NfhxQxWH",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformations\n",
        "\n",
        "from transformers import PretrainedConfig\n",
        "\n",
        "\n",
        "def create_transformation(freq: str, config: PretrainedConfig) -> Transformation:\n",
        "    remove_field_names = []\n",
        "    if config.num_static_real_features == 0:\n",
        "        remove_field_names.append(FieldName.FEAT_STATIC_REAL)\n",
        "    if config.num_dynamic_real_features == 0:\n",
        "        remove_field_names.append(FieldName.FEAT_DYNAMIC_REAL)\n",
        "    if config.num_static_categorical_features == 0:\n",
        "        remove_field_names.append(FieldName.FEAT_STATIC_CAT)\n",
        "\n",
        "    # a bit like torchvision.transforms.Compose\n",
        "    return Chain(\n",
        "        # step 1: remove static/dynamic fields if not specified\n",
        "        [RemoveFields(field_names=remove_field_names)]\n",
        "        # step 2: convert the data to NumPy (potentially not needed)\n",
        "        + (\n",
        "            [\n",
        "                AsNumpyArray(\n",
        "                    field=FieldName.FEAT_STATIC_CAT,\n",
        "                    expected_ndim=1,\n",
        "                    dtype=int,\n",
        "                )\n",
        "            ]\n",
        "            if config.num_static_categorical_features > 0\n",
        "            else []\n",
        "        )\n",
        "        + (\n",
        "            [\n",
        "                AsNumpyArray(\n",
        "                    field=FieldName.FEAT_STATIC_REAL,\n",
        "                    expected_ndim=1,\n",
        "                )\n",
        "            ]\n",
        "            if config.num_static_real_features > 0\n",
        "            else []\n",
        "        )\n",
        "        + [\n",
        "            AsNumpyArray(\n",
        "                field=FieldName.TARGET,\n",
        "                # we expect an extra dim for the multivariate case:\n",
        "                expected_ndim=1 if config.input_size == 1 else 2,\n",
        "            ),\n",
        "            # step 3: handle the NaN's by filling in the target with zero\n",
        "            # and return the mask (which is in the observed values)\n",
        "            # true for observed values, false for nan's\n",
        "            # the decoder uses this mask (no loss is incurred for unobserved values)\n",
        "            # see loss_weights inside the xxxForPrediction model\n",
        "            AddObservedValuesIndicator(\n",
        "                target_field=FieldName.TARGET,\n",
        "                output_field=FieldName.OBSERVED_VALUES,\n",
        "            ),\n",
        "            # step 4: add temporal features based on freq of the dataset\n",
        "            # month of year in the case when freq=\"M\"\n",
        "            # these serve as positional encodings\n",
        "            AddTimeFeatures(\n",
        "                start_field=FieldName.START,\n",
        "                target_field=FieldName.TARGET,\n",
        "                output_field=FieldName.FEAT_TIME,\n",
        "                time_features=time_features_from_frequency_str(freq),\n",
        "                pred_length=config.prediction_length,\n",
        "            ),\n",
        "            # step 5: add another temporal feature (just a single number)\n",
        "            # tells the model where in the life the value of the time series is\n",
        "            # sort of running counter\n",
        "            AddAgeFeature(\n",
        "                target_field=FieldName.TARGET,\n",
        "                output_field=FieldName.FEAT_AGE,\n",
        "                pred_length=config.prediction_length,\n",
        "                log_scale=True,\n",
        "            ),\n",
        "            # step 6: vertically stack all the temporal features into the key FEAT_TIME\n",
        "            VstackFeatures(\n",
        "                output_field=FieldName.FEAT_TIME,\n",
        "                input_fields=[FieldName.FEAT_TIME, FieldName.FEAT_AGE]\n",
        "                + (\n",
        "                    [FieldName.FEAT_DYNAMIC_REAL]\n",
        "                    if config.num_dynamic_real_features > 0\n",
        "                    else []\n",
        "                ),\n",
        "            ),\n",
        "            # step 7: rename to match HuggingFace names\n",
        "            RenameFields(\n",
        "                mapping={\n",
        "                    FieldName.FEAT_STATIC_CAT: \"static_categorical_features\",\n",
        "                    FieldName.FEAT_STATIC_REAL: \"static_real_features\",\n",
        "                    FieldName.FEAT_TIME: \"time_features\",\n",
        "                    FieldName.TARGET: \"values\",\n",
        "                    FieldName.OBSERVED_VALUES: \"observed_mask\",\n",
        "                }\n",
        "            ),\n",
        "        ]\n",
        "    )"
      ],
      "metadata": {
        "id": "Zv3EHWLlQ31G"
      },
      "id": "Zv3EHWLlQ31G",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instance Splitter\n",
        "\n",
        "from gluonts.transform.sampler import InstanceSampler\n",
        "from typing import Optional\n",
        "\n",
        "\n",
        "def create_instance_splitter(\n",
        "    config: PretrainedConfig,\n",
        "    mode: str,\n",
        "    train_sampler: Optional[InstanceSampler] = None,\n",
        "    validation_sampler: Optional[InstanceSampler] = None,\n",
        ") -> Transformation:\n",
        "    assert mode in [\"train\", \"validation\", \"test\"]\n",
        "\n",
        "    instance_sampler = {\n",
        "        \"train\": train_sampler\n",
        "        or ExpectedNumInstanceSampler(\n",
        "            num_instances=1.0, min_future=config.prediction_length\n",
        "        ),\n",
        "        \"validation\": validation_sampler\n",
        "        or ValidationSplitSampler(min_future=config.prediction_length),\n",
        "        \"test\": TestSplitSampler(),\n",
        "    }[mode]\n",
        "\n",
        "    return InstanceSplitter(\n",
        "        target_field=\"values\",\n",
        "        is_pad_field=FieldName.IS_PAD,\n",
        "        start_field=FieldName.START,\n",
        "        forecast_start_field=FieldName.FORECAST_START,\n",
        "        instance_sampler=instance_sampler,\n",
        "        past_length=config.context_length + max(config.lags_sequence),\n",
        "        future_length=config.prediction_length,\n",
        "        time_series_fields=[\"time_features\", \"observed_mask\"],\n",
        "    )"
      ],
      "metadata": {
        "id": "rD8HByHnQ5LJ"
      },
      "id": "rD8HByHnQ5LJ",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoaders\n",
        "\n",
        "from typing import Iterable\n",
        "\n",
        "import torch\n",
        "from gluonts.itertools import Cyclic, Cached\n",
        "from gluonts.dataset.loader import as_stacked_batches\n",
        "\n",
        "\n",
        "def create_train_dataloader(\n",
        "    config: PretrainedConfig,\n",
        "    freq,\n",
        "    data,\n",
        "    batch_size: int,\n",
        "    num_batches_per_epoch: int,\n",
        "    shuffle_buffer_length: Optional[int] = None,\n",
        "    cache_data: bool = True,\n",
        "    **kwargs,\n",
        ") -> Iterable:\n",
        "    PREDICTION_INPUT_NAMES = [\n",
        "        \"past_time_features\",\n",
        "        \"past_values\",\n",
        "        \"past_observed_mask\",\n",
        "        \"future_time_features\",\n",
        "    ]\n",
        "    if config.num_static_categorical_features > 0:\n",
        "        PREDICTION_INPUT_NAMES.append(\"static_categorical_features\")\n",
        "\n",
        "    if config.num_static_real_features > 0:\n",
        "        PREDICTION_INPUT_NAMES.append(\"static_real_features\")\n",
        "\n",
        "    TRAINING_INPUT_NAMES = PREDICTION_INPUT_NAMES + [\n",
        "        \"future_values\",\n",
        "        \"future_observed_mask\",\n",
        "    ]\n",
        "\n",
        "    transformation = create_transformation(freq, config)\n",
        "    transformed_data = transformation.apply(data, is_train=True)\n",
        "    if cache_data:\n",
        "        transformed_data = Cached(transformed_data)\n",
        "\n",
        "    # we initialize a Training instance\n",
        "    instance_splitter = create_instance_splitter(config, \"train\")\n",
        "\n",
        "    # the instance splitter will sample a window of\n",
        "    # context length + lags + prediction length (from the multiple possible transformed time series)\n",
        "    # randomly from within the target time series and return an iterator.\n",
        "    stream = Cyclic(transformed_data).stream()\n",
        "    training_instances = instance_splitter.apply(stream)\n",
        "\n",
        "    return as_stacked_batches(\n",
        "        training_instances,\n",
        "        batch_size=batch_size,\n",
        "        shuffle_buffer_length=shuffle_buffer_length,\n",
        "        field_names=TRAINING_INPUT_NAMES,\n",
        "        output_type=torch.tensor,\n",
        "        num_batches_per_epoch=num_batches_per_epoch,\n",
        "    )\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "VD703C44RSMz"
      },
      "id": "VD703C44RSMz",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Backtest dataloader\n",
        "\n",
        "def create_backtest_dataloader(\n",
        "    config: PretrainedConfig,\n",
        "    freq,\n",
        "    data,\n",
        "    batch_size: int,\n",
        "    **kwargs,\n",
        "):\n",
        "    PREDICTION_INPUT_NAMES = [\n",
        "        \"past_time_features\",\n",
        "        \"past_values\",\n",
        "        \"past_observed_mask\",\n",
        "        \"future_time_features\",\n",
        "    ]\n",
        "    if config.num_static_categorical_features > 0:\n",
        "        PREDICTION_INPUT_NAMES.append(\"static_categorical_features\")\n",
        "\n",
        "    if config.num_static_real_features > 0:\n",
        "        PREDICTION_INPUT_NAMES.append(\"static_real_features\")\n",
        "\n",
        "    transformation = create_transformation(freq, config)\n",
        "    transformed_data = transformation.apply(data)\n",
        "\n",
        "    # We create a Validation Instance splitter which will sample the very last\n",
        "    # context window seen during training only for the encoder.\n",
        "    instance_sampler = create_instance_splitter(config, \"validation\")\n",
        "\n",
        "    # we apply the transformations in train mode\n",
        "    testing_instances = instance_sampler.apply(transformed_data, is_train=True)\n",
        "\n",
        "    return as_stacked_batches(\n",
        "        testing_instances,\n",
        "        batch_size=batch_size,\n",
        "        output_type=torch.tensor,\n",
        "        field_names=PREDICTION_INPUT_NAMES,\n",
        "    )"
      ],
      "metadata": {
        "id": "eMEH9arpRhd5"
      },
      "id": "eMEH9arpRhd5",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HuggingFace default settings\n",
        "\n",
        "train_dataloader = create_train_dataloader(\n",
        "    config=config,\n",
        "    freq=freq,\n",
        "    data=train_split,  # use the split subset\n",
        "    batch_size=256,\n",
        "    num_batches_per_epoch=100,\n",
        ")\n",
        "\n",
        "test_dataloader = create_backtest_dataloader(\n",
        "    config=config,\n",
        "    freq=freq,\n",
        "    data=test_split,   # use the split subset\n",
        "    batch_size=64,\n",
        ")\n"
      ],
      "metadata": {
        "id": "YoiJDMvhRxrc"
      },
      "id": "YoiJDMvhRxrc",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch check\n",
        "\n",
        "batch = next(iter(train_dataloader))\n",
        "for k, v in batch.items():\n",
        "    print(k, v.shape, v.type())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDSQlxgCR2p1",
        "outputId": "0f9a7552-f9b8-48b8-c80c-f4e3b9398414"
      },
      "id": "cDSQlxgCR2p1",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "past_time_features torch.Size([256, 1193, 4]) torch.FloatTensor\n",
            "past_values torch.Size([256, 1193]) torch.FloatTensor\n",
            "past_observed_mask torch.Size([256, 1193]) torch.FloatTensor\n",
            "future_time_features torch.Size([256, 50, 4]) torch.FloatTensor\n",
            "static_categorical_features torch.Size([256, 1]) torch.LongTensor\n",
            "future_values torch.Size([256, 50]) torch.FloatTensor\n",
            "future_observed_mask torch.Size([256, 50]) torch.FloatTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time_features = time_features_from_frequency_str(\"D\")\n",
        "print(\"Number of time features from frequency:\", len(time_features))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pb3IFAKNTxxq",
        "outputId": "be0f913b-3fcd-4f39-8c6f-caf7e36a15b5"
      },
      "id": "Pb3IFAKNTxxq",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of time features from frequency: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Singular forward pass\n",
        "\n",
        "outputs = model(\n",
        "    past_values=batch[\"past_values\"],\n",
        "    past_time_features=batch[\"past_time_features\"],\n",
        "    past_observed_mask=batch[\"past_observed_mask\"],\n",
        "    static_categorical_features=batch[\"static_categorical_features\"]\n",
        "    if config.num_static_categorical_features > 0\n",
        "    else None,\n",
        "    static_real_features=batch[\"static_real_features\"]\n",
        "    if config.num_static_real_features > 0\n",
        "    else None,\n",
        "    future_values=batch[\"future_values\"],\n",
        "    future_time_features=batch[\"future_time_features\"],\n",
        "    future_observed_mask=batch[\"future_observed_mask\"],\n",
        "    output_hidden_states=True,\n",
        ")\n",
        "\n",
        "print(\"Loss:\", outputs.loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oO1byonTPCy",
        "outputId": "ba2ed873-a52c-4a22-dd77-29ec3c8f3f41"
      },
      "id": "-oO1byonTPCy",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: -11.861154556274414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train our model"
      ],
      "metadata": {
        "id": "e4qEMInzV8a7"
      },
      "id": "e4qEMInzV8a7"
    },
    {
      "cell_type": "code",
      "source": [
        "from accelerate import Accelerator\n",
        "from torch.optim import AdamW\n",
        "\n",
        "accelerator = Accelerator()\n",
        "device = accelerator.device\n",
        "\n",
        "model.to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=6e-4, betas=(0.9, 0.95), weight_decay=1e-1)\n",
        "\n",
        "model, optimizer, train_dataloader = accelerator.prepare(\n",
        "    model,\n",
        "    optimizer,\n",
        "    train_dataloader,\n",
        ")\n",
        "\n",
        "model.train()\n",
        "for epoch in range(40):\n",
        "    for idx, batch in enumerate(train_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(\n",
        "            static_categorical_features=batch[\"static_categorical_features\"].to(device)\n",
        "            if config.num_static_categorical_features > 0\n",
        "            else None,\n",
        "            static_real_features=batch[\"static_real_features\"].to(device)\n",
        "            if config.num_static_real_features > 0\n",
        "            else None,\n",
        "            past_time_features=batch[\"past_time_features\"].to(device),\n",
        "            past_values=batch[\"past_values\"].to(device),\n",
        "            future_time_features=batch[\"future_time_features\"].to(device),\n",
        "            future_values=batch[\"future_values\"].to(device),\n",
        "            past_observed_mask=batch[\"past_observed_mask\"].to(device),\n",
        "            future_observed_mask=batch[\"future_observed_mask\"].to(device),\n",
        "        )\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Backpropagation\n",
        "        accelerator.backward(loss)\n",
        "        optimizer.step()\n",
        "\n",
        "        if idx % 100 == 0:\n",
        "            print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "id": "6Lc7BGDvV8Ec",
        "outputId": "beae6118-96a8-4ecf-ed34-f7d7503eb1a5"
      },
      "id": "6Lc7BGDvV8Ec",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-11.31205940246582\n",
            "-11.837017059326172\n",
            "-13.384695053100586\n",
            "-13.87793254852295\n",
            "-14.047611236572266\n",
            "-13.947809219360352\n",
            "-13.08434772491455\n",
            "-14.31692123413086\n",
            "-14.89931869506836\n",
            "-14.332098007202148\n",
            "-14.309226036071777\n",
            "-15.266388893127441\n",
            "-14.746110916137695\n",
            "-15.214975357055664\n",
            "-15.53933334350586\n",
            "-15.06649398803711\n",
            "-15.434723854064941\n",
            "-15.164606094360352\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-603d7645726c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2244\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlomo_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2245\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2246\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_trigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Inference"
      ],
      "metadata": {
        "id": "J2Rf0XTdXVWk"
      },
      "id": "J2Rf0XTdXVWk"
    },
    {
      "cell_type": "code",
      "source": [
        "# Gather forecasts\n",
        "\n",
        "model.eval()\n",
        "\n",
        "forecasts = []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    outputs = model.generate(\n",
        "        static_categorical_features=batch[\"static_categorical_features\"].to(device)\n",
        "        if config.num_static_categorical_features > 0\n",
        "        else None,\n",
        "        static_real_features=batch[\"static_real_features\"].to(device)\n",
        "        if config.num_static_real_features > 0\n",
        "        else None,\n",
        "        past_time_features=batch[\"past_time_features\"].to(device),\n",
        "        past_values=batch[\"past_values\"].to(device),\n",
        "        future_time_features=batch[\"future_time_features\"].to(device),\n",
        "        past_observed_mask=batch[\"past_observed_mask\"].to(device),\n",
        "    )\n",
        "    forecasts.append(outputs.sequences.cpu().numpy())"
      ],
      "metadata": {
        "id": "KwbCuN7jXWS_"
      },
      "id": "KwbCuN7jXWS_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forecasts[0].shape"
      ],
      "metadata": {
        "id": "nJPx0P0oXabA"
      },
      "id": "nJPx0P0oXabA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack\n",
        "\n",
        "forecasts = np.vstack(forecasts)\n",
        "print(forecasts.shape)"
      ],
      "metadata": {
        "id": "QxXNYExuXbBX"
      },
      "id": "QxXNYExuXbBX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate against ground-truth\n",
        "\n",
        "from evaluate import load\n",
        "from gluonts.time_feature import get_seasonality\n",
        "\n",
        "# Load metrics\n",
        "mase_metric = load(\"evaluate-metric/mase\")\n",
        "smape_metric = load(\"evaluate-metric/smape\")\n",
        "\n",
        "# Compute the median forecast for each series from our forecasts.\n",
        "# forecasts shape: (num_series_in_test, num_samples, prediction_length)\n",
        "forecast_median = np.median(forecasts, axis=1)\n",
        "\n",
        "mase_metrics = []\n",
        "smape_metrics = []\n",
        "# Here, we iterate over each time series in our test split.\n",
        "# Note: Our test_split (or validation_dataset) should contain the full series, so that\n",
        "# the last `prediction_length` points are the ground-truth.\n",
        "for item_id, ts in enumerate(test_split):\n",
        "    training_data = np.array(ts[\"target\"][:-prediction_length])\n",
        "    ground_truth = np.array(ts[\"target\"][-prediction_length:])\n",
        "\n",
        "    # Compute MASE metric\n",
        "    mase = mase_metric.compute(\n",
        "        predictions=forecast_median[item_id],\n",
        "        references=ground_truth,\n",
        "        training=training_data,\n",
        "        periodicity=get_seasonality(freq),\n",
        "    )\n",
        "    mase_metrics.append(mase[\"mase\"])\n",
        "\n",
        "    # Compute sMAPE metric\n",
        "    smape = smape_metric.compute(\n",
        "        predictions=forecast_median[item_id],\n",
        "        references=ground_truth,\n",
        "    )\n",
        "    smape_metrics.append(smape[\"smape\"])\n",
        "\n",
        "print(\"Average MASE:\", np.mean(mase_metrics))\n",
        "print(\"Average sMAPE:\", np.mean(smape_metrics))\n"
      ],
      "metadata": {
        "id": "eCVEnqOXXc0_"
      },
      "id": "eCVEnqOXXc0_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"MASE: {np.mean(mase_metrics)}\")\n",
        "print(f\"sMAPE: {np.mean(smape_metrics)}\")\n",
        "plt.scatter(mase_metrics, smape_metrics, alpha=0.3)\n",
        "plt.xlabel(\"MASE\")\n",
        "plt.ylabel(\"sMAPE\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R5cYWHsGXnYO"
      },
      "id": "R5cYWHsGXnYO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot our inference against ground truth data\n",
        "\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_full(ts_index):\n",
        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
        "\n",
        "    # Create a timestamp index for the entire series using the start time from test_split.\n",
        "    index = pd.period_range(\n",
        "        start=test_split[ts_index][\"start\"].to_timestamp(),\n",
        "        periods=len(test_split[ts_index][\"target\"]),\n",
        "        freq=freq,\n",
        "    ).to_timestamp()\n",
        "\n",
        "    # Plot the full actual series\n",
        "    ax.plot(index, test_split[ts_index][\"target\"], label=\"Actual\", color=\"blue\")\n",
        "\n",
        "    # Extract forecasts for this series.\n",
        "    # forecasts is assumed to be a stacked array with shape (num_test_series, num_samples, prediction_length)\n",
        "    forecast = forecasts[ts_index]  # shape: (num_samples, prediction_length)\n",
        "    median_forecast = np.median(forecast, axis=0)\n",
        "    forecast_mean = forecast.mean(axis=0)\n",
        "    forecast_std = forecast.std(axis=0)\n",
        "\n",
        "    # Overlay the forecast on the last 'prediction_length' points.\n",
        "    forecast_index = index[-prediction_length:]\n",
        "    ax.plot(forecast_index, median_forecast, label=\"Median Forecast\", color=\"orange\")\n",
        "    ax.fill_between(forecast_index,\n",
        "                    forecast_mean - forecast_std,\n",
        "                    forecast_mean + forecast_std,\n",
        "                    color=\"orange\",\n",
        "                    alpha=0.3,\n",
        "                    label=\"±1 std\")\n",
        "\n",
        "    # Set up the x-axis with appropriate date formatting\n",
        "    ax.xaxis.set_major_locator(mdates.MonthLocator(bymonth=(1, 7)))\n",
        "    ax.xaxis.set_minor_locator(mdates.MonthLocator())\n",
        "\n",
        "    ax.set_title(f\"Full Series: Actual and Forecast (Series {ts_index})\")\n",
        "    ax.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Usage: plot the full series for a chosen test series index.\n",
        "plot_full(int(input(\"Index to plot: \")))\n"
      ],
      "metadata": {
        "id": "PhX4lLuVYe6i"
      },
      "id": "PhX4lLuVYe6i",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
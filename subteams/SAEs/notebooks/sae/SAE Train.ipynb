{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b2e6582-f883-4190-9cb1-05fab0d2a5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import gzip\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "from lightning.pytorch import LightningModule, Trainer\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from sae import SparseAutoencoder\n",
    "from utils import load_activations\n",
    "from utils import prepare_residual_stream_data\n",
    "from train import train_sae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1956db2d-66b7-4942-a2e3-c48e76727f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Hyperparameters search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efd196fa-54b3-49eb-983f-ea5f889c45e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name='encoder.outer.residual3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "150d7481-834b-4305-941f-1cfab39caffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading activations from ../data/activations/random_solutions_activations_10k.pkl.gz...\n",
      "Loaded 9998 samples\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_dir = f\"sae.{layer_name}_{timestamp}\"\n",
    "os.makedirs(run_dir, exist_ok=True)\n",
    "checkpoint_dir = os.path.join(run_dir, \"checkpoints\")\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "filepath = '../data/activations/random_solutions_activations_10k.pkl.gz'\n",
    "collected_act = load_activations(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "553eaff2-ccf9-42c7-8600-0ffc09f6642b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset: 9998 samples, 1221206 total vectors\n"
     ]
    }
   ],
   "source": [
    "# Prepare the training data - now handles variable sequence lengths\n",
    "training_data_array = prepare_residual_stream_data(collected_act,site_name='residual_stream',layer_name=layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5025c0bd-6974-4dd4-bd3d-53be533b5946",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training using device: cuda\n",
      "[Early stopping] Epoch:0 Wait count reset (best: 0.012058)\n",
      "[Early stopping] Epoch:1 Wait count reset (best: 0.000316)\n",
      "[Early stopping] Epoch:2 Wait count reset (best: 0.000241)\n",
      "[Early stopping] Epoch:3 Wait count reset (best: 0.000209)\n",
      "[Early stopping] Epoch:4 Wait count reset (best: 0.000189)\n",
      "[Early stopping] Epoch:5 Wait count reset (best: 0.000175)\n",
      "[Early stopping] Epoch:6 Wait count reset (best: 0.000163)\n",
      "[Early stopping] Epoch:7 Wait count: 1/15\n",
      "[Early stopping] Epoch:8 Wait count reset (best: 0.000147)\n",
      "[Train] Epoch 10/150 - Loss: 0.000139\n",
      "[Early stopping] Epoch:9 Wait count: 1/15\n",
      "[Early stopping] Epoch:10 Wait count reset (best: 0.000134)\n",
      "[Early stopping] Epoch:11 Wait count: 1/15\n",
      "[Early stopping] Epoch:12 Wait count: 2/15\n",
      "[Early stopping] Epoch:13 Wait count reset (best: 0.000120)\n",
      "[Early stopping] Epoch:14 Wait count: 1/15\n",
      "[Early stopping] Epoch:15 Wait count: 2/15\n",
      "[Early stopping] Epoch:16 Wait count reset (best: 0.000110)\n",
      "[Early stopping] Epoch:17 Wait count: 1/15\n",
      "[Early stopping] Epoch:18 Wait count: 2/15\n",
      "[Train] Epoch 20/150 - Loss: 0.000101\n",
      "[Early stopping] Epoch:19 Wait count: 3/15\n",
      "[Early stopping] Epoch:20 Wait count reset (best: 0.000100)\n",
      "[Early stopping] Epoch:21 Wait count: 1/15\n",
      "[Early stopping] Epoch:22 Wait count: 2/15\n",
      "[Early stopping] Epoch:23 Wait count: 3/15\n",
      "[Early stopping] Epoch:24 Wait count: 4/15\n",
      "[Early stopping] Epoch:25 Wait count: 5/15\n",
      "[Early stopping] Epoch:26 Wait count reset (best: 0.000088)\n",
      "[Early stopping] Epoch:27 Wait count: 1/15\n",
      "[Early stopping] Epoch:28 Wait count: 2/15\n",
      "[Train] Epoch 30/150 - Loss: 0.000084\n",
      "[Early stopping] Epoch:29 Wait count: 3/15\n",
      "[Early stopping] Epoch:30 Wait count: 4/15\n",
      "[Early stopping] Epoch:31 Wait count: 5/15\n",
      "[Early stopping] Epoch:32 Wait count: 6/15\n",
      "[Early stopping] Epoch:33 Wait count: 7/15\n",
      "[Early stopping] Epoch:34 Wait count reset (best: 0.000077)\n",
      "[Early stopping] Epoch:35 Wait count: 1/15\n",
      "[Early stopping] Epoch:36 Wait count: 2/15\n",
      "[Early stopping] Epoch:37 Wait count: 3/15\n",
      "[Early stopping] Epoch:38 Wait count: 4/15\n",
      "[Train] Epoch 40/150 - Loss: 0.000073\n",
      "[Early stopping] Epoch:39 Wait count: 5/15\n",
      "[Early stopping] Epoch:40 Wait count: 6/15\n",
      "[Early stopping] Epoch:41 Wait count: 7/15\n",
      "[Early stopping] Epoch:42 Wait count: 8/15\n",
      "[Early stopping] Epoch:43 Wait count: 9/15\n",
      "[Early stopping] Epoch:44 Wait count: 10/15\n",
      "[Early stopping] Epoch:45 Wait count: 11/15\n",
      "[Early stopping] Epoch:46 Wait count reset (best: 0.000067)\n",
      "[Early stopping] Epoch:47 Wait count: 1/15\n",
      "[Early stopping] Epoch:48 Wait count: 2/15\n",
      "[Train] Epoch 50/150 - Loss: 0.000065\n",
      "[Early stopping] Epoch:49 Wait count: 3/15\n",
      "[Early stopping] Epoch:50 Wait count: 4/15\n",
      "[Early stopping] Epoch:51 Wait count: 5/15\n",
      "[Early stopping] Epoch:52 Wait count: 6/15\n",
      "[Early stopping] Epoch:53 Wait count: 7/15\n",
      "[Early stopping] Epoch:54 Wait count: 8/15\n",
      "[Early stopping] Epoch:55 Wait count: 9/15\n",
      "[Early stopping] Epoch:56 Wait count: 10/15\n",
      "[Early stopping] Epoch:57 Wait count: 11/15\n",
      "[Early stopping] Epoch:58 Wait count: 12/15\n",
      "[Train] Epoch 60/150 - Loss: 0.000059\n",
      "[Early stopping] Epoch:59 Wait count: 13/15\n",
      "[Early stopping] Epoch:60 Wait count: 14/15\n",
      "[Early stopping] Epoch:61 Wait count: 15/15\n",
      "[Early stopping] Triggered after 61 epochs\n",
      "[Train] Final model saved to sae.encoder.outer.residual3_20250309_213613/checkpoints/sae_final.pt\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 256\n",
    "# Create dataset and dataloader\n",
    "training_data = torch.tensor(training_data_array, dtype=torch.float32)\n",
    "dataset = torch.utils.data.TensorDataset(training_data)\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "INPUT_DIM = 256\n",
    "LATENT_DIM = INPUT_DIM*5\n",
    "NUM_EPOCHS = 150\n",
    "LEARNING_RATE = 0.0004513970337767647\n",
    "L1_LAMBDA = 0.000407\n",
    "\n",
    "PATIENCE = 15\n",
    "MIN_DELTA = 1e-5\n",
    "\n",
    "# Create and train the model\n",
    "model = SparseAutoencoder(input_dim=INPUT_DIM, latent_dim=LATENT_DIM,name=layer_name)\n",
    "trained_model, best_loss = train_sae(\n",
    "    model, data_loader, num_epochs=NUM_EPOCHS, \n",
    "    learning_rate=LEARNING_RATE, l1_lambda=L1_LAMBDA,\n",
    "    device=device, checkpoint_dir=checkpoint_dir,\n",
    "    patience=PATIENCE, min_delta=MIN_DELTA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaf17b6-304d-4dd2-aa47-3b45cc7027cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odeformer-wsl",
   "language": "python",
   "name": "odeformer-wsl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
